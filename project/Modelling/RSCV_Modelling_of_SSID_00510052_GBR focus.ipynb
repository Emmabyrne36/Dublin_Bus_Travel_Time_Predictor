{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First set number of cores on machine to use and SSID number to analyse, then run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting variables\n",
    "\n",
    "cores = 3 # enter the number of cores to use here, in place of x\n",
    "SSIDno = 510052 # enter the SSID number to model as an int here, in place of xxxxxxxx\n",
    "iters = 38 # enter the number of randomised search iterations here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.patches as mpatches\n",
    "#import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "import autotime\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "#import seaborn as sns\n",
    "import statsmodels as stm\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression as LinR\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data processing stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, select route files to input based on SSIDno to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a Inputting data and creating dataframe for SSIDno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "# Read in stop_times.txt and trips.txt files from NTA data\n",
    "stop_times_2012 = pd.read_csv('stop_times.txt')\n",
    "trips_2012 = pd.read_csv('trips.txt')\n",
    "\n",
    "# Merge by trip_id\n",
    "merge = pd.merge(stop_times_2012, trips_2012, on='trip_id', how='outer')\n",
    "\n",
    "# Keep only necessary columns\n",
    "merge.drop(['arrival_time','departure_time','pickup_type','drop_off_type','service_id','shape_dist_traveled'], axis=1, inplace=True)\n",
    "\n",
    "# Transform trip_id to route and stop_id to StopID\n",
    "merge['route_short'] = merge['trip_id'].apply(lambda x: x[x.index('-')+1:])\n",
    "merge['route_short'] = merge['route_short'].apply(lambda x: x[: x.index('-')])\n",
    "merge['route_short'] = merge['route_short'].apply(lambda x: str(x).zfill(4))\n",
    "merge['StopID'] = merge['stop_id'].apply(lambda x: x[-4:])\n",
    "\n",
    "# Find StopID and the sequence of that shape_id\n",
    "gb = merge.groupby(['shape_id', 'route_short', 'direction_id','stop_sequence', 'StopID'])\n",
    "gbc = gb.count()\n",
    "gbc.reset_index(['shape_id', 'route_short', 'direction_id','stop_sequence', 'StopID'], inplace=True)\n",
    "transit_shapeID_stopID = gbc.drop(['trip_id','stop_id','route_id','trip_headsign'], axis=1)\n",
    "\n",
    "# create list of pairs of routes and the SSIDs contained within them\n",
    "ssid = []\n",
    "for i in range(len(transit_shapeID_stopID.index)-1):\n",
    "    temp = transit_shapeID_stopID['StopID'].iloc[i] + transit_shapeID_stopID['StopID'].iloc[i+1]\n",
    "    ssid.append([ transit_shapeID_stopID['route_short'].iloc[i],temp])\n",
    "    \n",
    "SSIDnoStr = str(SSIDno).zfill(8)\n",
    "routes = [x for x in ssid if SSIDnoStr in x[1]]\n",
    "routes = [item[0] for item in routes]\n",
    "routes = list(set(routes))\n",
    "\n",
    "# Reading in the route CSV files for the required SSID\n",
    "\n",
    "res = pd.read_csv('Route_XXXX_travel_time_csvs/Blank_Route_travel_time.csv')\n",
    "route_list = routes\n",
    "for r in route_list:\n",
    "    df = pd.read_csv('Route_XXXX_travel_time_csvs/Route_%s_travel_time.csv' % r)\n",
    "    res = pd.concat([df, res], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25259, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 342 ms\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for SSIDno\n",
    "\n",
    "res['SSID'] = res['SSID'].astype('category')\n",
    "ssid_df = res[res.SSID == SSIDno]\n",
    "ssid_df.reset_index(inplace=True)\n",
    "ssid_df = ssid_df.drop('index', axis=1)\n",
    "ssid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38 unique JPIDs traversing this segment, over the course of 25259 observations.\n",
      "time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "JPID_Count = ssid_df.JourneyPatternID.unique().shape[0]\n",
    "Row_Count = ssid_df.shape[0]\n",
    "print(\"There are\", JPID_Count, \"unique JPIDs traversing this segment, over the course of\", Row_Count, \"observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "# add leading zeroes to JourneyPatternID\n",
    "\n",
    "ssid_df.JourneyPatternID = ssid_df.JourneyPatternID.astype('object')\n",
    "ssid_df.JourneyPatternID = ssid_df.JourneyPatternID.apply(lambda x: str(x).zfill(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b Adding extra features and altering/dropping existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "# adding Xbuses feature - boolean feature indicating whether or not the JourneyPatternID represents an express (X) bus\n",
    "\n",
    "ssid_df['XBuses'] = ssid_df[ssid_df[\"JourneyPatternID\"].str.find(\"X\") > 0].sum(axis=1) > 0\n",
    "ssid_df[\"XBuses\"].fillna(False, inplace=True)\n",
    "ssid_df['XBuses'] = ssid_df['XBuses'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25259, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "# adding JPID_length feature - represents the total number of stops traversed by this JourneyPatternID along its entire route\n",
    "\n",
    "JPIDL = pd.read_csv('JPID_Length.csv')\n",
    "JPIDL = JPIDL.drop('Unnamed: 0', axis=1)\n",
    "ssid_df = pd.merge(left=ssid_df ,right=JPIDL, how='left', left_on='JourneyPatternID', right_on='JourneyPatternID')\n",
    "ssid_df = ssid_df.dropna()\n",
    "ssid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "# removing non-holiday-period weekends from SchoolHoliday feature to avoid multi-collinearity issues\n",
    "\n",
    "ssid_df['SchoolHoliday'] = ssid_df['SchoolHoliday'].astype('int')\n",
    "ssid_df['SchoolHoliday'] = np.where(ssid_df['TimeFrame'].isin(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "# dropping unneeded columns\n",
    "\n",
    "ssid_df = ssid_df.drop(['SourceStopID', 'DestStopID', 'VehicleJourneyID', 'JourneyPatternID', 'SSID'], axis=1)\n",
    "\n",
    "# reordering remaining columns\n",
    "\n",
    "ssid_df = ssid_df[['TravelTime', 'Rain', 'WindSpeed', 'JPID_length', 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36 ms\n"
     ]
    }
   ],
   "source": [
    "# assigning appropriate datatypes where necessary\n",
    "\n",
    "ssid_df['Day'] = ssid_df['Day'].astype('category')\n",
    "ssid_df['HourFrame'] = ssid_df['HourFrame'].astype('category')\n",
    "ssid_df['JPID_length'] = ssid_df['JPID_length'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "# removing any constant features\n",
    "# code from: https://stackoverflow.com/questions/20209600/panda-dataframe-remove-constant-column\n",
    "\n",
    "ssid_df = ssid_df.loc[:,ssid_df.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TravelTime</th>\n",
       "      <th>Rain</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>JPID_length</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Day</th>\n",
       "      <th>HourFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>61</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25229</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25230</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25231</th>\n",
       "      <td>57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25232</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25233</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25234</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25235</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25236</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25237</th>\n",
       "      <td>93</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25238</th>\n",
       "      <td>21</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25239</th>\n",
       "      <td>41</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25240</th>\n",
       "      <td>18</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25242</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>41</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25244</th>\n",
       "      <td>18</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25245</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25246</th>\n",
       "      <td>19</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>14.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25248</th>\n",
       "      <td>41</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>30.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25249</th>\n",
       "      <td>41</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>25.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25250</th>\n",
       "      <td>20</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>26.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25251</th>\n",
       "      <td>108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25252</th>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25253</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25254</th>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25255</th>\n",
       "      <td>79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25256</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25257</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25258</th>\n",
       "      <td>80</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25259 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TravelTime      Rain  WindSpeed  JPID_length  SchoolHoliday        Day  \\\n",
       "0             139  0.000000       15.0           80              0    Tuesday   \n",
       "1              80  0.000000       17.5           80              0    Tuesday   \n",
       "2              20  0.000000       17.0           80              0    Tuesday   \n",
       "3              43  0.000000       14.0           80              0    Tuesday   \n",
       "4             100  0.000000       15.0           80              0    Tuesday   \n",
       "5              57  0.000000       17.5           80              0    Tuesday   \n",
       "6              23  0.000000       14.0           80              0    Tuesday   \n",
       "7              80  0.000000       15.0           80              0    Tuesday   \n",
       "8              39  0.000000       17.5           80              0    Tuesday   \n",
       "9              61  0.000000       16.5           80              0    Tuesday   \n",
       "10             23  0.000000       14.0           80              0    Tuesday   \n",
       "11             79  0.000000       16.0           80              0    Tuesday   \n",
       "12            101  0.000000       15.0           80              0    Tuesday   \n",
       "13             80  0.000000       17.5           80              0    Tuesday   \n",
       "14             59  0.000000       16.5           80              0    Tuesday   \n",
       "15             43  0.000000       16.0           80              0    Tuesday   \n",
       "16             20  0.000000       16.0           80              0    Tuesday   \n",
       "17             39  0.000000       15.5           80              0    Tuesday   \n",
       "18             59  0.000000       17.5           80              0    Tuesday   \n",
       "19             20  0.000000       16.5           80              0    Tuesday   \n",
       "20             41  0.000000       16.0           80              0    Tuesday   \n",
       "21             22  0.000000       16.0           80              0    Tuesday   \n",
       "22             42  0.000000       15.5           80              0    Tuesday   \n",
       "23             20  0.000000       15.5           80              0    Tuesday   \n",
       "24             43  0.000000       17.5           80              0    Tuesday   \n",
       "25             20  0.000000       15.5           80              0    Tuesday   \n",
       "26             39  0.000000       15.5           80              0    Tuesday   \n",
       "27             21  0.000000       17.5           80              0    Tuesday   \n",
       "28            118  0.000000       15.5           80              0    Tuesday   \n",
       "29             61  0.000000       16.0           80              0    Tuesday   \n",
       "...           ...       ...        ...          ...            ...        ...   \n",
       "25229          21  0.000000        2.5           47              0    Tuesday   \n",
       "25230         100  0.000000        4.0           47              0  Wednesday   \n",
       "25231          57  0.000000       10.0           47              0  Wednesday   \n",
       "25232          20  0.000000        4.5           47              0  Wednesday   \n",
       "25233          20  0.000000        4.0           47              0  Wednesday   \n",
       "25234          29  0.000000        2.5           47              0   Thursday   \n",
       "25235          20  0.000000        7.0           47              0   Thursday   \n",
       "25236          23  0.000000        7.0           47              0   Thursday   \n",
       "25237          93  0.233333        9.0           47              0     Friday   \n",
       "25238          21  0.233333       21.0           47              0     Friday   \n",
       "25239          41  2.966667       12.0           47              0     Friday   \n",
       "25240          18  2.766667       14.0           47              0     Friday   \n",
       "25241          20  0.000000        9.5           47              0   Saturday   \n",
       "25242          20  0.000000       14.5           47              0   Saturday   \n",
       "25243          41  0.133333       19.0           47              0   Saturday   \n",
       "25244          18  0.133333       19.0           47              0   Saturday   \n",
       "25245          20  0.000000       26.0           47              0     Sunday   \n",
       "25246          19  0.066667       14.5           47              0     Sunday   \n",
       "25247          59  0.000000       15.5           47              0     Monday   \n",
       "25248          41  0.166667       30.5           47              0     Monday   \n",
       "25249          41  0.033333       25.5           47              0     Monday   \n",
       "25250          20  0.033333       26.5           47              0     Monday   \n",
       "25251         108  0.000000        7.0           47              0    Tuesday   \n",
       "25252          43  0.000000       25.5           47              0    Tuesday   \n",
       "25253          20  0.000000       18.0           47              0    Tuesday   \n",
       "25254          43  0.000000       21.5           47              0    Tuesday   \n",
       "25255          79  0.000000       19.0           47              0  Wednesday   \n",
       "25256          39  0.000000       16.0           47              0  Wednesday   \n",
       "25257          18  0.000000       15.0           47              0  Wednesday   \n",
       "25258          80  0.700000       22.0           47              0   Thursday   \n",
       "\n",
       "      HourFrame  \n",
       "0             8  \n",
       "1            11  \n",
       "2            14  \n",
       "3            18  \n",
       "4             8  \n",
       "5            11  \n",
       "6            21  \n",
       "7             8  \n",
       "8            11  \n",
       "9            15  \n",
       "10           18  \n",
       "11           22  \n",
       "12            8  \n",
       "13           12  \n",
       "14           15  \n",
       "15           19  \n",
       "16           22  \n",
       "17            9  \n",
       "18           12  \n",
       "19           15  \n",
       "20           19  \n",
       "21           22  \n",
       "22            9  \n",
       "23            9  \n",
       "24           12  \n",
       "25           16  \n",
       "26            9  \n",
       "27           12  \n",
       "28           16  \n",
       "29           19  \n",
       "...         ...  \n",
       "25229        18  \n",
       "25230         8  \n",
       "25231        13  \n",
       "25232        20  \n",
       "25233        18  \n",
       "25234         8  \n",
       "25235        13  \n",
       "25236        18  \n",
       "25237         8  \n",
       "25238        13  \n",
       "25239        20  \n",
       "25240        18  \n",
       "25241         8  \n",
       "25242        13  \n",
       "25243        18  \n",
       "25244        18  \n",
       "25245        13  \n",
       "25246        20  \n",
       "25247         8  \n",
       "25248        13  \n",
       "25249        20  \n",
       "25250        18  \n",
       "25251         8  \n",
       "25252        13  \n",
       "25253        20  \n",
       "25254        18  \n",
       "25255         8  \n",
       "25256        20  \n",
       "25257        18  \n",
       "25258         8  \n",
       "\n",
       "[25259 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "ssid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Dropping Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising range of travel-time data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histiogram of values (x-axis is number of seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c7407f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA68AAAHVCAYAAAAevs1nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXgEAABie8AoAAMDwhFcAAACG9/8CRY0vrQqGIjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c740fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 233 ms\n"
     ]
    }
   ],
   "source": [
    "ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28089e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHVCAYAAAA+QbhCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28051320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 248 ms\n"
     ]
    }
   ],
   "source": [
    "ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25259.000000\n",
       "mean        47.010491\n",
       "std         26.665890\n",
       "min          1.000000\n",
       "25%         21.000000\n",
       "50%         41.000000\n",
       "75%         61.000000\n",
       "max        402.000000\n",
       "Name: TravelTime, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "# Checking stats for TravelTime\n",
    "\n",
    "ssid_df.TravelTime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.62081178308\n",
      "time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "# loading table of minimum times to traverse segments at 65kmph\n",
    "\n",
    "find_lb = pd.read_csv('use_speed_and_distance_get_outlier_bound.csv')\n",
    "\n",
    "# extracting value for this segment, to use as lower bound for outlier removal\n",
    "\n",
    "lb = find_lb.loc[find_lb['SSID'] == SSIDno, 'min_sec'].iloc[0]\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There will be 32 outliers dropped.\n",
      "time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "# make a copy of original df\n",
    "\n",
    "trimssid_df = ssid_df.copy()\n",
    "\n",
    "# Remove TravelTime upper bound outliers beyond 3 x IQR, and lowerbound below 'lb'\n",
    "\n",
    "ub = trimssid_df.quantile(q=.75) + (3*(trimssid_df.quantile(q=.75)-trimssid_df.quantile(q=.25)))\n",
    "trimssid_df['OutlierTT'] = (trimssid_df['TravelTime'] < lb) | (trimssid_df['TravelTime'] > ub['TravelTime'])\n",
    "\n",
    "# Outlier rows counted\n",
    "\n",
    "Outlier_Count = trimssid_df[(trimssid_df['OutlierTT'] == True)].shape[0]\n",
    "Row_Count = Row_Count - Outlier_Count\n",
    "\n",
    "print(\"There will be\", Outlier_Count, \"outliers dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41 ms\n"
     ]
    }
   ],
   "source": [
    "# dropping outliers\n",
    "\n",
    "trimssid_df = trimssid_df[trimssid_df.OutlierTT != True]\n",
    "trimssid_df.sort_values(['TravelTime'], ascending=False, inplace=True)\n",
    "trimssid_df = trimssid_df.drop(['OutlierTT'], axis=1)\n",
    "trimssid_df.reset_index(inplace=True)\n",
    "trimssid_df = trimssid_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25227.000000\n",
       "mean        46.969794\n",
       "std         26.336399\n",
       "min          9.000000\n",
       "25%         21.000000\n",
       "50%         41.000000\n",
       "75%         61.000000\n",
       "max        179.000000\n",
       "Name: TravelTime, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8 ms\n"
     ]
    }
   ],
   "source": [
    "# Create TT mean/median value variables, to use in calculating mean/median absolute percentage accuracy scores\n",
    "# and for horizontal lines in the charts below to represent the mean/medium\n",
    "\n",
    "ssid_df = trimssid_df\n",
    "ssid_df_mean = ssid_df.TravelTime.mean()\n",
    "ssid_df_median  = ssid_df.TravelTime.median()\n",
    "ssid_df.TravelTime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising range of data after dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x281ea0f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA68AAAHVCAYAAAAevs1nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMMTrwAAAAzv/wODMzJOn87Y5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a23efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 212 ms\n"
     ]
    }
   ],
   "source": [
    "ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a169c88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHVCAYAAAA+QbhCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njv1/Ty+upe+Gr+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a0d8198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 247 ms\n"
     ]
    }
   ],
   "source": [
    "ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ai Bar plot for mean TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x281eee48>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAF3CAYAAADU/LhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDEZRAwAAGMz/B4t8dhb0F+ONAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a6151d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "mean_HF = ssid_df.groupby('HourFrame')['TravelTime'].mean()\n",
    "mean_HF.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 25\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2aii Bar plot for median TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28211f28>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAF3CAYAAADU/LhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a1e6ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "med_HF = ssid_df.groupby('HourFrame')['TravelTime'].median()\n",
    "med_HF.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 25\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2bi Bar plot for mean TravelTime per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a0ccd68>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAF3CAYAAADU/LhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x281877b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "mean_Day = ssid_df.groupby('Day')['TravelTime'].mean()\n",
    "mean_Day=mean_Day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "mean_Day.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2bii Bar plot for median TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a22f668>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAF3CAYAAADU/LhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a22af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "med_Day = ssid_df.groupby('Day')['TravelTime'].median()\n",
    "\n",
    "med_Day=med_Day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "med_Day.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ci Bar plot for mean TravelTime when SchoolHoliday true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a5977b8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAF3CAYAAADU/LhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a597240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "mean_SH = ssid_df.groupby('SchoolHoliday')['TravelTime'].mean()\n",
    "mean_SH.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2cii Bar plot for median TravelTime when SchoolHoliday true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2badacc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAF3CAYAAADU/LhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBoAAMBg/j8kT+tSNLqxuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bada710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "med_SH = ssid_df.groupby('SchoolHoliday')['TravelTime'].median()\n",
    "med_SH.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% for training and 30% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model training (Scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to dreate dummy variables for categorical features, and split into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare data for modelling via Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TravelTime</th>\n",
       "      <th>Rain</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>JPID_length</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>HF_6</th>\n",
       "      <th>HF_7</th>\n",
       "      <th>HF_8</th>\n",
       "      <th>HF_9</th>\n",
       "      <th>HF_10</th>\n",
       "      <th>...</th>\n",
       "      <th>HF_20</th>\n",
       "      <th>HF_21</th>\n",
       "      <th>HF_22</th>\n",
       "      <th>HF_23</th>\n",
       "      <th>Day_Monday</th>\n",
       "      <th>Day_Saturday</th>\n",
       "      <th>Day_Sunday</th>\n",
       "      <th>Day_Thursday</th>\n",
       "      <th>Day_Tuesday</th>\n",
       "      <th>Day_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.5</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.5</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>157</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>4.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>155</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>3.5</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>145</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.5</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>139</td>\n",
       "      <td>0.666504</td>\n",
       "      <td>16.0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25197</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25198</th>\n",
       "      <td>12</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25199</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25200</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25201</th>\n",
       "      <td>12</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>21.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25202</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25203</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25204</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25205</th>\n",
       "      <td>11</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>4.5</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25206</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25207</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25208</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25209</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25210</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25211</th>\n",
       "      <td>11</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>13.5</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25212</th>\n",
       "      <td>11</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25213</th>\n",
       "      <td>10</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25214</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25215</th>\n",
       "      <td>10</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>9.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25216</th>\n",
       "      <td>10</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>9.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25218</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25219</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25220</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25221</th>\n",
       "      <td>10</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>4.5</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25222</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25223</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25224</th>\n",
       "      <td>9</td>\n",
       "      <td>0.633301</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25225</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25226</th>\n",
       "      <td>9</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25227 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TravelTime      Rain  WindSpeed  JPID_length  SchoolHoliday  HF_6  \\\n",
       "0             179  0.000000        3.0           62              0     0   \n",
       "1             174  0.000000       11.5           59              0     0   \n",
       "2             162  0.000000       13.5           93              0     0   \n",
       "3             160  0.000000        6.0           59              0     0   \n",
       "4             160  0.000000       17.5           93              0     0   \n",
       "5             159  0.000000        6.0           62              0     0   \n",
       "6             157  0.899902        4.5           53              0     0   \n",
       "7             156  0.000000       21.5           80              0     0   \n",
       "8             155  1.266667        3.5           48              0     0   \n",
       "9             153  0.000000        2.5           80              0     0   \n",
       "10            146  0.000000       10.5           80              0     0   \n",
       "11            145  0.100000        9.0           60              0     0   \n",
       "12            144  0.000000        2.5           76              0     0   \n",
       "13            144  0.000000        5.0           53              0     0   \n",
       "14            143  0.000000       19.0           62              0     0   \n",
       "15            142  0.000000       26.5           53              0     0   \n",
       "16            142  0.000000        2.5           44              0     0   \n",
       "17            142  0.000000       17.0           93              1     0   \n",
       "18            141  0.000000        4.0           53              0     0   \n",
       "19            141  0.000000        2.0           53              0     0   \n",
       "20            141  0.000000       14.5           42              0     0   \n",
       "21            141  0.000000       20.5           62              0     0   \n",
       "22            141  0.000000        8.0           93              0     0   \n",
       "23            140  0.000000        2.0           93              0     0   \n",
       "24            140  0.000000        5.0           62              0     0   \n",
       "25            140  0.000000       13.5           62              0     0   \n",
       "26            140  0.000000       10.0           80              0     0   \n",
       "27            139  0.000000        9.5           76              0     0   \n",
       "28            139  0.666504       16.0           93              0     0   \n",
       "29            139  0.000000       10.0           76              0     0   \n",
       "...           ...       ...        ...          ...            ...   ...   \n",
       "25197          12  0.000000        6.5           42              0     0   \n",
       "25198          12  0.700195       22.0           44              0     0   \n",
       "25199          12  0.000000       13.5           53              0     0   \n",
       "25200          12  0.000000       10.5           59              0     0   \n",
       "25201          12  0.100000       21.5           42              0     0   \n",
       "25202          12  0.000000       20.5           80              0     0   \n",
       "25203          11  0.000000        2.5           53              0     0   \n",
       "25204          11  0.000000        3.0           63              0     0   \n",
       "25205          11  1.533333        4.5           76              0     0   \n",
       "25206          11  0.000000        3.0           62              0     0   \n",
       "25207          11  0.000000       15.5           76              0     0   \n",
       "25208          11  0.000000       10.5           76              0     0   \n",
       "25209          11  0.000000        8.0           80              0     0   \n",
       "25210          11  0.000000        3.5           80              0     0   \n",
       "25211          11  0.033325       13.5           62              0     0   \n",
       "25212          11  0.033325       11.0           44              0     0   \n",
       "25213          10  0.033325        9.0           53              0     0   \n",
       "25214          10  0.000000        6.0           80              0     0   \n",
       "25215          10  0.033325        9.0           41              0     0   \n",
       "25216          10  0.066667        9.5           42              0     0   \n",
       "25217          10  0.000000        9.5           53              0     0   \n",
       "25218          10  0.000000        6.5           53              0     0   \n",
       "25219          10  0.000000       18.5           53              0     0   \n",
       "25220          10  0.000000        9.5           92              1     0   \n",
       "25221          10  0.733333        4.5           76              0     0   \n",
       "25222          10  0.000000        2.5           53              0     0   \n",
       "25223           9  0.000000        7.5           42              0     0   \n",
       "25224           9  0.633301        4.0           44              0     0   \n",
       "25225           9  0.000000       11.0           42              1     0   \n",
       "25226           9  0.066650        5.0           53              0     0   \n",
       "\n",
       "       HF_7  HF_8  HF_9  HF_10      ...        HF_20  HF_21  HF_22  HF_23  \\\n",
       "0         0     0     0      0      ...            0      0      0      0   \n",
       "1         0     0     0      0      ...            0      0      0      0   \n",
       "2         0     0     0      0      ...            0      0      0      0   \n",
       "3         0     0     0      0      ...            0      0      0      0   \n",
       "4         0     0     0      0      ...            0      0      0      0   \n",
       "5         0     0     0      0      ...            0      0      0      0   \n",
       "6         0     0     0      0      ...            0      0      0      0   \n",
       "7         0     0     0      1      ...            0      0      0      0   \n",
       "8         0     1     0      0      ...            0      0      0      0   \n",
       "9         0     0     0      0      ...            0      0      0      0   \n",
       "10        0     0     0      1      ...            0      0      0      0   \n",
       "11        0     1     0      0      ...            0      0      0      0   \n",
       "12        0     0     0      0      ...            0      0      0      0   \n",
       "13        0     0     0      0      ...            0      0      0      0   \n",
       "14        0     1     0      0      ...            0      0      0      0   \n",
       "15        0     0     0      0      ...            0      0      0      0   \n",
       "16        0     0     0      0      ...            0      0      0      0   \n",
       "17        0     0     1      0      ...            0      0      0      0   \n",
       "18        0     0     0      0      ...            0      0      0      0   \n",
       "19        0     0     1      0      ...            0      0      0      0   \n",
       "20        0     0     0      0      ...            0      0      0      0   \n",
       "21        0     1     0      0      ...            0      0      0      0   \n",
       "22        0     0     0      0      ...            0      0      0      0   \n",
       "23        0     0     0      0      ...            0      0      0      0   \n",
       "24        0     0     0      1      ...            0      0      0      0   \n",
       "25        0     0     0      0      ...            0      0      0      0   \n",
       "26        0     0     0      0      ...            0      0      0      0   \n",
       "27        0     0     0      0      ...            0      0      0      0   \n",
       "28        0     0     1      0      ...            0      0      0      0   \n",
       "29        0     0     1      0      ...            0      0      0      0   \n",
       "...     ...   ...   ...    ...      ...          ...    ...    ...    ...   \n",
       "25197     0     0     0      0      ...            0      0      0      0   \n",
       "25198     0     1     0      0      ...            0      0      0      0   \n",
       "25199     0     0     0      0      ...            0      0      0      0   \n",
       "25200     0     0     0      0      ...            0      0      0      0   \n",
       "25201     0     0     0      0      ...            0      0      0      0   \n",
       "25202     0     0     0      0      ...            0      0      0      0   \n",
       "25203     0     0     0      0      ...            0      0      0      0   \n",
       "25204     0     0     1      0      ...            0      0      0      0   \n",
       "25205     0     0     1      0      ...            0      0      0      0   \n",
       "25206     0     0     0      1      ...            0      0      0      0   \n",
       "25207     0     0     0      0      ...            0      0      0      0   \n",
       "25208     0     0     0      0      ...            0      0      0      0   \n",
       "25209     0     0     0      0      ...            0      0      0      0   \n",
       "25210     0     0     0      0      ...            0      0      0      0   \n",
       "25211     0     0     0      0      ...            0      0      0      0   \n",
       "25212     0     0     1      0      ...            0      0      0      0   \n",
       "25213     1     0     0      0      ...            0      0      0      0   \n",
       "25214     0     0     0      0      ...            0      0      0      0   \n",
       "25215     1     0     0      0      ...            0      0      0      0   \n",
       "25216     0     0     0      0      ...            0      0      0      0   \n",
       "25217     0     0     0      0      ...            0      0      0      0   \n",
       "25218     0     0     0      0      ...            0      0      0      0   \n",
       "25219     0     0     1      0      ...            0      0      0      0   \n",
       "25220     0     1     0      0      ...            0      0      0      0   \n",
       "25221     0     0     0      0      ...            0      0      0      0   \n",
       "25222     0     0     0      0      ...            0      0      0      0   \n",
       "25223     0     0     0      0      ...            0      0      0      0   \n",
       "25224     0     0     0      0      ...            0      0      0      0   \n",
       "25225     0     0     0      0      ...            0      0      0      0   \n",
       "25226     0     0     0      0      ...            0      0      0      0   \n",
       "\n",
       "       Day_Monday  Day_Saturday  Day_Sunday  Day_Thursday  Day_Tuesday  \\\n",
       "0               0             0           0             0            0   \n",
       "1               0             0           0             0            0   \n",
       "2               0             0           0             0            0   \n",
       "3               0             0           1             0            0   \n",
       "4               0             0           0             0            1   \n",
       "5               0             0           0             0            0   \n",
       "6               0             1           0             0            0   \n",
       "7               0             0           0             1            0   \n",
       "8               1             0           0             0            0   \n",
       "9               0             0           0             0            0   \n",
       "10              1             0           0             0            0   \n",
       "11              1             0           0             0            0   \n",
       "12              0             0           0             0            0   \n",
       "13              0             0           0             0            0   \n",
       "14              0             0           0             0            0   \n",
       "15              1             0           0             0            0   \n",
       "16              0             0           0             0            0   \n",
       "17              0             0           0             0            0   \n",
       "18              0             0           0             0            0   \n",
       "19              0             0           0             1            0   \n",
       "20              1             0           0             0            0   \n",
       "21              1             0           0             0            0   \n",
       "22              0             0           0             0            0   \n",
       "23              0             0           0             0            1   \n",
       "24              0             0           0             1            0   \n",
       "25              0             0           0             0            0   \n",
       "26              0             0           0             1            0   \n",
       "27              0             0           0             1            0   \n",
       "28              0             0           0             0            0   \n",
       "29              0             0           0             0            0   \n",
       "...           ...           ...         ...           ...          ...   \n",
       "25197           0             0           0             1            0   \n",
       "25198           0             0           0             1            0   \n",
       "25199           1             0           0             0            0   \n",
       "25200           0             0           0             0            0   \n",
       "25201           0             0           0             0            0   \n",
       "25202           0             0           0             0            1   \n",
       "25203           0             0           0             0            1   \n",
       "25204           0             0           0             0            1   \n",
       "25205           1             0           0             0            0   \n",
       "25206           0             0           0             0            1   \n",
       "25207           0             0           0             0            0   \n",
       "25208           0             1           0             0            0   \n",
       "25209           0             0           0             0            1   \n",
       "25210           0             1           0             0            0   \n",
       "25211           1             0           0             0            0   \n",
       "25212           1             0           0             0            0   \n",
       "25213           1             0           0             0            0   \n",
       "25214           0             0           0             1            0   \n",
       "25215           1             0           0             0            0   \n",
       "25216           1             0           0             0            0   \n",
       "25217           0             0           0             0            0   \n",
       "25218           0             0           0             1            0   \n",
       "25219           0             0           0             1            0   \n",
       "25220           0             0           0             1            0   \n",
       "25221           0             0           0             0            0   \n",
       "25222           0             0           0             0            0   \n",
       "25223           0             0           0             0            1   \n",
       "25224           0             0           0             0            0   \n",
       "25225           0             0           0             0            0   \n",
       "25226           0             0           0             0            0   \n",
       "\n",
       "       Day_Wednesday  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  1  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  0  \n",
       "9                  0  \n",
       "10                 0  \n",
       "11                 0  \n",
       "12                 0  \n",
       "13                 0  \n",
       "14                 1  \n",
       "15                 0  \n",
       "16                 0  \n",
       "17                 1  \n",
       "18                 0  \n",
       "19                 0  \n",
       "20                 0  \n",
       "21                 0  \n",
       "22                 1  \n",
       "23                 0  \n",
       "24                 0  \n",
       "25                 0  \n",
       "26                 0  \n",
       "27                 0  \n",
       "28                 0  \n",
       "29                 0  \n",
       "...              ...  \n",
       "25197              0  \n",
       "25198              0  \n",
       "25199              0  \n",
       "25200              1  \n",
       "25201              0  \n",
       "25202              0  \n",
       "25203              0  \n",
       "25204              0  \n",
       "25205              0  \n",
       "25206              0  \n",
       "25207              0  \n",
       "25208              0  \n",
       "25209              0  \n",
       "25210              0  \n",
       "25211              0  \n",
       "25212              0  \n",
       "25213              0  \n",
       "25214              0  \n",
       "25215              0  \n",
       "25216              0  \n",
       "25217              1  \n",
       "25218              0  \n",
       "25219              0  \n",
       "25220              0  \n",
       "25221              1  \n",
       "25222              1  \n",
       "25223              0  \n",
       "25224              1  \n",
       "25225              0  \n",
       "25226              1  \n",
       "\n",
       "[25227 rows x 29 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55 ms\n"
     ]
    }
   ],
   "source": [
    "# create dummy variables from HourFrame and Day using get_dummies\n",
    "# dropping first values to avoid multicollinearity (Day = Friday, Hour = 0 or 6 or 7, depending on SSID)\n",
    "\n",
    "Day_dummies = pd.get_dummies(ssid_df.Day, prefix='Day', drop_first=True)\n",
    "HF_dummies = pd.get_dummies(ssid_df.HourFrame, prefix='HF', drop_first=True)\n",
    "\n",
    "# concatenate the dummy variable columns onto the original DataFrame and drop the original features\n",
    "ssid_df = pd.concat([ssid_df, HF_dummies, Day_dummies], axis=1)\n",
    "ssid_df = ssid_df.drop(['HourFrame', 'Day'], axis=1)\n",
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rain', 'WindSpeed', 'JPID_length', 'SchoolHoliday', 'HF_6', 'HF_7', 'HF_8', 'HF_9', 'HF_10', 'HF_11', 'HF_12', 'HF_13', 'HF_14', 'HF_15', 'HF_16', 'HF_17', 'HF_18', 'HF_19', 'HF_20', 'HF_21', 'HF_22', 'HF_23', 'Day_Monday', 'Day_Saturday', 'Day_Sunday', 'Day_Thursday', 'Day_Tuesday', 'Day_Wednesday']\n",
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "# prepare a list containing all remaining features bar the target\n",
    "pred_features = list(ssid_df)\n",
    "pred_features.remove('TravelTime')\n",
    "print(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "# prepare target/predictive feature variables for use in scikit-learn modelling\n",
    "\n",
    "X = ssid_df[pred_features]\n",
    "y = ssid_df['TravelTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "# split the data into training portion (70%) and final testing potion (30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison purposes, first train on Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2a Linear Regression model (via scikit-learn) - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=3, normalize=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 66 ms\n"
     ]
    }
   ],
   "source": [
    "lr = LinR(n_jobs = cores)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the Linear Regression model is 0.0850064179834\n",
      "\n",
      "The mean absolute error of the Linear Regression model is 20.8236740141\n",
      "The mean absolute percentage error is 44.3341818685\n",
      "\n",
      "The median absolute error of the Linear Regression model is 18.6411493973\n",
      "The median absolute percentage error is 45.4662180423\n",
      "time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_pred = lr.predict(X_train)\n",
    "lr_rsq = metrics.r2_score(y_train, lr_pred)\n",
    "print (\"The R-squared value of the Linear Regression model is\", lr_rsq)\n",
    "print()\n",
    "lr_mae = metrics.mean_absolute_error(y_train, lr_pred)\n",
    "print (\"The mean absolute error of the Linear Regression model is\", lr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((lr_mae)/ssid_df_mean)*100))\n",
    "print()\n",
    "lr_mdae = metrics.median_absolute_error(y_train, lr_pred)\n",
    "print (\"The median absolute error of the Linear Regression model is\", lr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((lr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2b Linear Regression model (via scikit-learn) - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the Linear Regression model is 0.0807977997354\n",
      "\n",
      "The mean absolute error of the Linear Regression model is 20.8338561091\n",
      "The mean absolute percentage error is 44.3558598325\n",
      "\n",
      "The median absolute error of the Linear Regression model is 18.3697215585\n",
      "The median absolute percentage error is 44.8041989231\n",
      "time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "lr_preda = lr.predict(X_test)\n",
    "lr_rsqa = metrics.r2_score(y_test, lr_preda)\n",
    "print (\"The R-squared value of the Linear Regression model is\", lr_rsqa)\n",
    "print()\n",
    "lr_maea = metrics.mean_absolute_error(y_test, lr_preda)\n",
    "print (\"The mean absolute error of the Linear Regression model is\", lr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((lr_maea)/ssid_df_mean)*100))\n",
    "print()\n",
    "lr_mdaea = metrics.median_absolute_error(y_test, lr_preda)\n",
    "print (\"The median absolute error of the Linear Regression model is\", lr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((lr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3a Gradient Boosting Regression model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 864 ms\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR()\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered feature ranking:\n",
      "JPID_length \t 0.231495996182\n",
      "WindSpeed \t 0.071853633702\n",
      "Day_Saturday \t 0.0612350095247\n",
      "HF_22 \t 0.0572814722609\n",
      "Day_Sunday \t 0.0552237206918\n",
      "HF_23 \t 0.0542190442923\n",
      "Rain \t 0.0440822048973\n",
      "HF_6 \t 0.0433515775409\n",
      "HF_8 \t 0.0429384046994\n",
      "HF_7 \t 0.041592245077\n",
      "HF_18 \t 0.0388209227875\n",
      "SchoolHoliday \t 0.0370165158081\n",
      "HF_21 \t 0.0369487357429\n",
      "HF_20 \t 0.030741601356\n",
      "HF_19 \t 0.0189354163998\n",
      "HF_14 \t 0.0170676473376\n",
      "HF_11 \t 0.0165589940057\n",
      "HF_10 \t 0.0165163677448\n",
      "HF_15 \t 0.0158753013585\n",
      "Day_Tuesday \t 0.0149644533374\n",
      "HF_13 \t 0.0111535314544\n",
      "Day_Monday \t 0.0109592059282\n",
      "HF_17 \t 0.00973670384316\n",
      "HF_12 \t 0.00866547948032\n",
      "Day_Wednesday \t 0.00696867083177\n",
      "Day_Thursday \t 0.00325862621117\n",
      "HF_9 \t 0.00253851750471\n",
      "HF_16 \t 0.0\n",
      "time: 67 ms\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.115591252046\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 20.439160861\n",
      "The mean absolute percentage error is 43.5155426577\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.786560409\n",
      "The median absolute percentage error is 45.8208790464\n",
      "time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3b Gradient Boosting Regression model - - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.103421042408\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 20.502981222\n",
      "The mean absolute percentage error is 43.6514179836\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.8798968585\n",
      "The median absolute percentage error is 46.0485289232\n",
      "time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4a Gradient Boosting Regression model - training - LAD loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='lad', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='lad')\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered feature ranking:\n",
      "JPID_length \t 0.249988913776\n",
      "HF_23 \t 0.0948097735095\n",
      "WindSpeed \t 0.0795180100504\n",
      "HF_22 \t 0.0765864561434\n",
      "Day_Saturday \t 0.0754048183533\n",
      "Rain \t 0.0724072822202\n",
      "HF_7 \t 0.0653238346924\n",
      "Day_Sunday \t 0.0369570079175\n",
      "HF_18 \t 0.0345793998308\n",
      "HF_8 \t 0.0302463374377\n",
      "SchoolHoliday \t 0.0277349371108\n",
      "HF_21 \t 0.0254730318326\n",
      "HF_20 \t 0.0213430327044\n",
      "HF_10 \t 0.0137383530386\n",
      "HF_15 \t 0.0121885621609\n",
      "HF_12 \t 0.0118421252626\n",
      "HF_6 \t 0.011633703865\n",
      "HF_14 \t 0.0112450036857\n",
      "Day_Wednesday \t 0.00888917840329\n",
      "Day_Tuesday \t 0.0085468799361\n",
      "HF_11 \t 0.00820146129025\n",
      "HF_17 \t 0.00765899480735\n",
      "Day_Thursday \t 0.0045327687781\n",
      "HF_13 \t 0.00410391338751\n",
      "HF_19 \t 0.00285329459704\n",
      "Day_Monday \t 0.00231450084843\n",
      "HF_9 \t 0.00187842435973\n",
      "HF_16 \t 0.0\n",
      "time: 64 ms\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.0072312096281\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 19.8138748049\n",
      "The mean absolute percentage error is 42.1842912316\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.6631564531\n",
      "The median absolute percentage error is 45.5198937881\n",
      "time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4b Gradient Boosting Regression model - testing - LAD loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.00182247441133\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 19.8056852021\n",
      "The mean absolute percentage error is 42.1668553392\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.6175969446\n",
      "The median absolute percentage error is 45.4087730357\n",
      "time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5a Gradient Boosting Regression model - training - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='huber', max_depth=3,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered feature ranking:\n",
      "JPID_length \t 0.211636508891\n",
      "Day_Sunday \t 0.0715075236527\n",
      "WindSpeed \t 0.0643243518767\n",
      "Day_Saturday \t 0.0628098582149\n",
      "HF_22 \t 0.0585749301691\n",
      "HF_23 \t 0.0530106578761\n",
      "HF_8 \t 0.0440482803846\n",
      "HF_21 \t 0.0440198967844\n",
      "HF_6 \t 0.0418466029439\n",
      "Rain \t 0.0411060724784\n",
      "HF_18 \t 0.0398181433491\n",
      "SchoolHoliday \t 0.0384330957089\n",
      "HF_7 \t 0.0376401223132\n",
      "HF_20 \t 0.0317198622754\n",
      "HF_19 \t 0.0182850979246\n",
      "Day_Tuesday \t 0.0181951387033\n",
      "HF_14 \t 0.0175147668027\n",
      "HF_11 \t 0.0173384095476\n",
      "HF_15 \t 0.0150272450021\n",
      "HF_10 \t 0.0143935137639\n",
      "Day_Thursday \t 0.0115272202711\n",
      "HF_17 \t 0.0111288440394\n",
      "HF_13 \t 0.0108068444361\n",
      "HF_12 \t 0.00927013141625\n",
      "Day_Monday \t 0.00843153877386\n",
      "Day_Wednesday \t 0.00672507722574\n",
      "HF_9 \t 0.000860265175186\n",
      "HF_16 \t 0.0\n",
      "time: 67 ms\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.107892825971\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 20.1744527512\n",
      "The mean absolute percentage error is 42.9519717206\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.1164413926\n",
      "The median absolute percentage error is 44.1864424209\n",
      "time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5b Gradient Boosting Regression model - testing - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.0969503458815\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 20.2203951257\n",
      "The mean absolute percentage error is 43.0497843152\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.2813002584\n",
      "The median absolute percentage error is 44.5885372157\n",
      "time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Parameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that there are 38 unique JPIDs traversing this segment, over the course of 25227 observations.\n",
      "Error in callback <bound method LineWatcher.stop of <autotime.LineWatcher object at 0x0000000008560710>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\autotime.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mformat_delta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Note that there are\", JPID_Count, \"unique JPIDs traversing this segment, over the course of\", Row_Count, \"observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-df044ab76723>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-df044ab76723>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    STOP HERE - from results above, select best loss function for each of the three trainings below,\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP HERE - from results above, select best loss function for each of the three trainings below,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a Gradient Boosted Regression with RandomizedSearchCV (scikit), Kfold 5, 5 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with Median Absolute Error as scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(75, 1500),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(5, 100),\n",
    "            'min_samples_split': stats.randint(200, 1000),\n",
    "            'learning_rate': stats.uniform(0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='huber', max_depth=3,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=38, n_jobs=3,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000002A8D62B0>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000002BB41A58>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000002BB3BDD8>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000002BB8C2E8>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000002BB89630>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True,\n",
       "          scoring=make_scorer(median_absolute_error, greater_is_better=False),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17min 30s\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.median_absolute_error, greater_is_better=False))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found:\n",
      "{'learning_rate': 0.18056030838343398, 'max_depth': 9, 'min_samples_leaf': 99, 'min_samples_split': 422, 'n_estimators': 692}\n",
      "time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MdAE found is 17.8211994307\n",
      "Best MdAPE found is 43.466%\n",
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_train_MdAE = abs(gbr_rsearch.best_score_)\n",
    "gbr_train_MdAPE = (gbr_train_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"Best MdAE found is\", gbr_train_MdAE)\n",
    "print (\"Best MdAPE found is\", str(round(gbr_train_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full ranked results for GBR RandomizedSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-15.336240</td>\n",
       "      <td>-17.821199</td>\n",
       "      <td>692</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>422</td>\n",
       "      <td>0.18056</td>\n",
       "      <td>25.3728</td>\n",
       "      <td>0.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-15.596957</td>\n",
       "      <td>-17.824060</td>\n",
       "      <td>525</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>623</td>\n",
       "      <td>0.209484</td>\n",
       "      <td>17.8260</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-15.887270</td>\n",
       "      <td>-17.850941</td>\n",
       "      <td>1210</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>642</td>\n",
       "      <td>0.124596</td>\n",
       "      <td>32.3318</td>\n",
       "      <td>0.1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-16.178293</td>\n",
       "      <td>-17.874762</td>\n",
       "      <td>638</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>483</td>\n",
       "      <td>0.0673676</td>\n",
       "      <td>22.2122</td>\n",
       "      <td>0.0728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.027615</td>\n",
       "      <td>-17.892511</td>\n",
       "      <td>843</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>257</td>\n",
       "      <td>0.112025</td>\n",
       "      <td>33.4998</td>\n",
       "      <td>0.1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-15.909393</td>\n",
       "      <td>-17.904420</td>\n",
       "      <td>209</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>678</td>\n",
       "      <td>0.287509</td>\n",
       "      <td>6.8732</td>\n",
       "      <td>0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-15.257931</td>\n",
       "      <td>-17.921527</td>\n",
       "      <td>1358</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>417</td>\n",
       "      <td>0.267143</td>\n",
       "      <td>34.5630</td>\n",
       "      <td>0.1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-15.301028</td>\n",
       "      <td>-17.929877</td>\n",
       "      <td>1129</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>792</td>\n",
       "      <td>0.296815</td>\n",
       "      <td>30.2382</td>\n",
       "      <td>0.1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-15.912222</td>\n",
       "      <td>-17.945631</td>\n",
       "      <td>1351</td>\n",
       "      <td>6</td>\n",
       "      <td>93</td>\n",
       "      <td>608</td>\n",
       "      <td>0.186793</td>\n",
       "      <td>31.9480</td>\n",
       "      <td>0.1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-16.640349</td>\n",
       "      <td>-17.954182</td>\n",
       "      <td>906</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>405</td>\n",
       "      <td>0.0501495</td>\n",
       "      <td>24.2454</td>\n",
       "      <td>0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-16.050394</td>\n",
       "      <td>-17.967984</td>\n",
       "      <td>1197</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>608</td>\n",
       "      <td>0.0930292</td>\n",
       "      <td>33.6578</td>\n",
       "      <td>0.1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-16.806284</td>\n",
       "      <td>-17.972982</td>\n",
       "      <td>378</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>529</td>\n",
       "      <td>0.0980605</td>\n",
       "      <td>8.9184</td>\n",
       "      <td>0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>-16.550595</td>\n",
       "      <td>-17.982798</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>402</td>\n",
       "      <td>0.286785</td>\n",
       "      <td>4.1720</td>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-16.468451</td>\n",
       "      <td>-17.984076</td>\n",
       "      <td>408</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>434</td>\n",
       "      <td>0.0957026</td>\n",
       "      <td>11.6800</td>\n",
       "      <td>0.0414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-16.266461</td>\n",
       "      <td>-17.987024</td>\n",
       "      <td>464</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>0.044841</td>\n",
       "      <td>16.3726</td>\n",
       "      <td>0.0554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-16.828392</td>\n",
       "      <td>-17.989479</td>\n",
       "      <td>1349</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>769</td>\n",
       "      <td>0.0524553</td>\n",
       "      <td>30.7952</td>\n",
       "      <td>0.1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-15.303609</td>\n",
       "      <td>-18.001776</td>\n",
       "      <td>1194</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>597</td>\n",
       "      <td>0.300929</td>\n",
       "      <td>29.5498</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-16.171605</td>\n",
       "      <td>-18.004248</td>\n",
       "      <td>900</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>651</td>\n",
       "      <td>0.0790213</td>\n",
       "      <td>26.3110</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>-16.725318</td>\n",
       "      <td>-18.008511</td>\n",
       "      <td>992</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>596</td>\n",
       "      <td>0.122383</td>\n",
       "      <td>17.6842</td>\n",
       "      <td>0.0634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>-17.216217</td>\n",
       "      <td>-18.018756</td>\n",
       "      <td>883</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>287</td>\n",
       "      <td>0.0396327</td>\n",
       "      <td>16.1710</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>-16.414368</td>\n",
       "      <td>-18.026559</td>\n",
       "      <td>618</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>726</td>\n",
       "      <td>0.199309</td>\n",
       "      <td>13.3718</td>\n",
       "      <td>0.0466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-16.650952</td>\n",
       "      <td>-18.032173</td>\n",
       "      <td>348</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>520</td>\n",
       "      <td>0.279464</td>\n",
       "      <td>5.8830</td>\n",
       "      <td>0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-16.930034</td>\n",
       "      <td>-18.054687</td>\n",
       "      <td>683</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>832</td>\n",
       "      <td>0.289052</td>\n",
       "      <td>9.2360</td>\n",
       "      <td>0.0366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-16.597312</td>\n",
       "      <td>-18.066898</td>\n",
       "      <td>760</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>382</td>\n",
       "      <td>0.261401</td>\n",
       "      <td>11.7392</td>\n",
       "      <td>0.0426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>-17.409660</td>\n",
       "      <td>-18.082049</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>641</td>\n",
       "      <td>0.199917</td>\n",
       "      <td>1.8744</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-16.811841</td>\n",
       "      <td>-18.157644</td>\n",
       "      <td>1311</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>844</td>\n",
       "      <td>0.244709</td>\n",
       "      <td>18.8352</td>\n",
       "      <td>0.0722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-17.404841</td>\n",
       "      <td>-18.166637</td>\n",
       "      <td>828</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>655</td>\n",
       "      <td>0.264333</td>\n",
       "      <td>8.4502</td>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>-17.531894</td>\n",
       "      <td>-18.180465</td>\n",
       "      <td>812</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>821</td>\n",
       "      <td>0.0584181</td>\n",
       "      <td>10.5128</td>\n",
       "      <td>0.0416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>-17.185320</td>\n",
       "      <td>-18.181587</td>\n",
       "      <td>838</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>237</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>8.9926</td>\n",
       "      <td>0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>-17.797424</td>\n",
       "      <td>-18.185849</td>\n",
       "      <td>1205</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>665</td>\n",
       "      <td>0.0361118</td>\n",
       "      <td>11.7912</td>\n",
       "      <td>0.0478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>-17.358592</td>\n",
       "      <td>-18.212053</td>\n",
       "      <td>288</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>431</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>4.9352</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>-17.635758</td>\n",
       "      <td>-18.220474</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>330</td>\n",
       "      <td>0.172899</td>\n",
       "      <td>3.0882</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>-17.446763</td>\n",
       "      <td>-18.225847</td>\n",
       "      <td>1443</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>850</td>\n",
       "      <td>0.194783</td>\n",
       "      <td>14.7734</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>-17.672618</td>\n",
       "      <td>-18.233647</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>570</td>\n",
       "      <td>0.15724</td>\n",
       "      <td>2.2320</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>-17.780268</td>\n",
       "      <td>-18.240254</td>\n",
       "      <td>927</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>869</td>\n",
       "      <td>0.0643713</td>\n",
       "      <td>8.9698</td>\n",
       "      <td>0.0368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>-17.627768</td>\n",
       "      <td>-18.294341</td>\n",
       "      <td>248</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>446</td>\n",
       "      <td>0.0686285</td>\n",
       "      <td>4.3062</td>\n",
       "      <td>0.0174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>-17.896500</td>\n",
       "      <td>-18.295197</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>642</td>\n",
       "      <td>0.261716</td>\n",
       "      <td>1.1010</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>-17.883746</td>\n",
       "      <td>-18.313504</td>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>983</td>\n",
       "      <td>0.0904629</td>\n",
       "      <td>2.4492</td>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_train_score  mean_test_score param_n_estimators  \\\n",
       "0                 1        -15.336240       -17.821199                692   \n",
       "1                 2        -15.596957       -17.824060                525   \n",
       "2                 3        -15.887270       -17.850941               1210   \n",
       "3                 4        -16.178293       -17.874762                638   \n",
       "4                 5        -15.027615       -17.892511                843   \n",
       "5                 6        -15.909393       -17.904420                209   \n",
       "6                 7        -15.257931       -17.921527               1358   \n",
       "7                 8        -15.301028       -17.929877               1129   \n",
       "8                 9        -15.912222       -17.945631               1351   \n",
       "9                10        -16.640349       -17.954182                906   \n",
       "10               11        -16.050394       -17.967984               1197   \n",
       "11               12        -16.806284       -17.972982                378   \n",
       "12               13        -16.550595       -17.982798                186   \n",
       "13               14        -16.468451       -17.984076                408   \n",
       "14               15        -16.266461       -17.987024                464   \n",
       "15               16        -16.828392       -17.989479               1349   \n",
       "16               17        -15.303609       -18.001776               1194   \n",
       "17               18        -16.171605       -18.004248                900   \n",
       "18               19        -16.725318       -18.008511                992   \n",
       "19               20        -17.216217       -18.018756                883   \n",
       "20               21        -16.414368       -18.026559                618   \n",
       "21               22        -16.650952       -18.032173                348   \n",
       "22               23        -16.930034       -18.054687                683   \n",
       "23               24        -16.597312       -18.066898                760   \n",
       "24               25        -17.409660       -18.082049                 81   \n",
       "25               26        -16.811841       -18.157644               1311   \n",
       "26               27        -17.404841       -18.166637                828   \n",
       "27               28        -17.531894       -18.180465                812   \n",
       "28               29        -17.185320       -18.181587                838   \n",
       "29               30        -17.797424       -18.185849               1205   \n",
       "30               31        -17.358592       -18.212053                288   \n",
       "31               32        -17.635758       -18.220474                300   \n",
       "32               33        -17.446763       -18.225847               1443   \n",
       "33               34        -17.672618       -18.233647                167   \n",
       "34               35        -17.780268       -18.240254                927   \n",
       "35               36        -17.627768       -18.294341                248   \n",
       "36               37        -17.896500       -18.295197                109   \n",
       "37               38        -17.883746       -18.313504                127   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0                9                     99                     422   \n",
       "1                9                     72                     623   \n",
       "2                7                     71                     642   \n",
       "3                9                     39                     483   \n",
       "4                9                     50                     257   \n",
       "5                9                      8                     678   \n",
       "6                6                     83                     417   \n",
       "7                7                     73                     792   \n",
       "8                6                     93                     608   \n",
       "9                7                     82                     405   \n",
       "10               7                     39                     608   \n",
       "11               7                     36                     529   \n",
       "12               6                     30                     402   \n",
       "13               8                     44                     434   \n",
       "14               9                     19                     227   \n",
       "15               7                     83                     769   \n",
       "16               6                     51                     597   \n",
       "17               8                     12                     651   \n",
       "18               5                     40                     596   \n",
       "19               5                     85                     287   \n",
       "20               6                     53                     726   \n",
       "21               5                      6                     520   \n",
       "22               4                     22                     832   \n",
       "23               4                     60                     382   \n",
       "24               7                     60                     641   \n",
       "25               4                     27                     844   \n",
       "26               3                     93                     655   \n",
       "27               4                     27                     821   \n",
       "28               3                     16                     237   \n",
       "29               3                     12                     665   \n",
       "30               5                     60                     431   \n",
       "31               3                     68                     330   \n",
       "32               3                     54                     850   \n",
       "33               4                     64                     570   \n",
       "34               3                     53                     869   \n",
       "35               5                     62                     446   \n",
       "36               3                     20                     642   \n",
       "37               6                     58                     983   \n",
       "\n",
       "   param_learning_rate  mean_fit_time  mean_score_time  \n",
       "0              0.18056        25.3728           0.0864  \n",
       "1             0.209484        17.8260           0.0600  \n",
       "2             0.124596        32.3318           0.1074  \n",
       "3            0.0673676        22.2122           0.0728  \n",
       "4             0.112025        33.4998           0.1024  \n",
       "5             0.287509         6.8732           0.0240  \n",
       "6             0.267143        34.5630           0.1122  \n",
       "7             0.296815        30.2382           0.1006  \n",
       "8             0.186793        31.9480           0.1070  \n",
       "9            0.0501495        24.2454           0.0862  \n",
       "10           0.0930292        33.6578           0.1116  \n",
       "11           0.0980605         8.9184           0.0326  \n",
       "12            0.286785         4.1720           0.0152  \n",
       "13           0.0957026        11.6800           0.0414  \n",
       "14            0.044841        16.3726           0.0554  \n",
       "15           0.0524553        30.7952           0.1128  \n",
       "16            0.300929        29.5498           0.0956  \n",
       "17           0.0790213        26.3110           0.0946  \n",
       "18            0.122383        17.6842           0.0634  \n",
       "19           0.0396327        16.1710           0.0584  \n",
       "20            0.199309        13.3718           0.0466  \n",
       "21            0.279464         5.8830           0.0228  \n",
       "22            0.289052         9.2360           0.0366  \n",
       "23            0.261401        11.7392           0.0426  \n",
       "24            0.199917         1.8744           0.0082  \n",
       "25            0.244709        18.8352           0.0722  \n",
       "26            0.264333         8.4502           0.0332  \n",
       "27           0.0584181        10.5128           0.0416  \n",
       "28              0.2333         8.9926           0.0350  \n",
       "29           0.0361118        11.7912           0.0478  \n",
       "30            0.105894         4.9352           0.0200  \n",
       "31            0.172899         3.0882           0.0126  \n",
       "32            0.194783        14.7734           0.0558  \n",
       "33             0.15724         2.2320           0.0102  \n",
       "34           0.0643713         8.9698           0.0368  \n",
       "35           0.0686285         4.3062           0.0174  \n",
       "36            0.261716         1.1010           0.0052  \n",
       "37           0.0904629         2.4492           0.0104  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_learning_rate', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of best model on the test set is 0.0577962747956\n",
      "\n",
      "Mean absolute error of best model on the test set is 20.448090416\n",
      "Mean absolute percentage error of best model on the test set is 49.873%\n",
      "\n",
      "Median absolute error of best model on the test set is 17.6412290653\n",
      "Median absolute percentage error of best model on the test set is 43.027%\n",
      "time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with Mean Absolute Error as scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(75, 1500),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(5, 100),\n",
    "            'min_samples_split': stats.randint(200, 1000),\n",
    "            'learning_rate': stats.uniform(0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='huber', max_depth=3,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=38, n_jobs=3,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000067E84E0>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000067E8A90>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000067E8C88>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000067E8D68>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000067E8F60>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True,\n",
       "          scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21min 6s\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.mean_absolute_error, greater_is_better=False))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found:\n",
      "{'learning_rate': 0.096418954632868911, 'max_depth': 9, 'min_samples_leaf': 87, 'min_samples_split': 690, 'n_estimators': 97}\n",
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean absolute error found is 20.2196033827\n",
      "Best Mean absolute percentage error found is 43.466%\n",
      "time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_train_MAE = abs(gbr_rsearch.best_score_)\n",
    "gbr_train_MAPE = (gbr_train_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"Best Mean absolute error found is\", gbr_train_MAE)\n",
    "print (\"Best Mean absolute percentage error found is\", str(round(gbr_train_MAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full ranked results for GBR RandomizedSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-19.643172</td>\n",
       "      <td>-20.219603</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>690</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>2.8340</td>\n",
       "      <td>0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-19.622397</td>\n",
       "      <td>-20.225150</td>\n",
       "      <td>278</td>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "      <td>591</td>\n",
       "      <td>0.0474928</td>\n",
       "      <td>6.6460</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-19.488935</td>\n",
       "      <td>-20.241858</td>\n",
       "      <td>972</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>725</td>\n",
       "      <td>0.0474484</td>\n",
       "      <td>15.6568</td>\n",
       "      <td>0.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-19.575668</td>\n",
       "      <td>-20.242302</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>85</td>\n",
       "      <td>927</td>\n",
       "      <td>0.261858</td>\n",
       "      <td>2.0752</td>\n",
       "      <td>0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-19.756980</td>\n",
       "      <td>-20.247097</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>402</td>\n",
       "      <td>0.152155</td>\n",
       "      <td>1.8074</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-19.397209</td>\n",
       "      <td>-20.247649</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>816</td>\n",
       "      <td>0.196402</td>\n",
       "      <td>3.1310</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-19.195216</td>\n",
       "      <td>-20.273595</td>\n",
       "      <td>1384</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>809</td>\n",
       "      <td>0.0505795</td>\n",
       "      <td>27.6146</td>\n",
       "      <td>0.1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-19.451504</td>\n",
       "      <td>-20.273762</td>\n",
       "      <td>1364</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>643</td>\n",
       "      <td>0.272337</td>\n",
       "      <td>14.4116</td>\n",
       "      <td>0.0560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-19.314743</td>\n",
       "      <td>-20.275938</td>\n",
       "      <td>242</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>474</td>\n",
       "      <td>0.10264</td>\n",
       "      <td>6.1448</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-19.197217</td>\n",
       "      <td>-20.278124</td>\n",
       "      <td>179</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>397</td>\n",
       "      <td>0.255524</td>\n",
       "      <td>3.1208</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-19.283857</td>\n",
       "      <td>-20.279669</td>\n",
       "      <td>912</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>833</td>\n",
       "      <td>0.0369084</td>\n",
       "      <td>23.8568</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-19.587199</td>\n",
       "      <td>-20.289760</td>\n",
       "      <td>1132</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>746</td>\n",
       "      <td>0.205171</td>\n",
       "      <td>11.7122</td>\n",
       "      <td>0.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>-19.632172</td>\n",
       "      <td>-20.297671</td>\n",
       "      <td>1406</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>470</td>\n",
       "      <td>0.134782</td>\n",
       "      <td>15.1524</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-19.253388</td>\n",
       "      <td>-20.304629</td>\n",
       "      <td>995</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>390</td>\n",
       "      <td>0.070252</td>\n",
       "      <td>17.7686</td>\n",
       "      <td>0.0642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-19.365190</td>\n",
       "      <td>-20.311878</td>\n",
       "      <td>876</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>280</td>\n",
       "      <td>0.289916</td>\n",
       "      <td>9.6548</td>\n",
       "      <td>0.0406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-19.153522</td>\n",
       "      <td>-20.323321</td>\n",
       "      <td>211</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>738</td>\n",
       "      <td>0.292026</td>\n",
       "      <td>4.2512</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-19.363450</td>\n",
       "      <td>-20.328112</td>\n",
       "      <td>672</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>962</td>\n",
       "      <td>0.294354</td>\n",
       "      <td>8.7104</td>\n",
       "      <td>0.0346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-18.970964</td>\n",
       "      <td>-20.342355</td>\n",
       "      <td>877</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>845</td>\n",
       "      <td>0.134671</td>\n",
       "      <td>17.9388</td>\n",
       "      <td>0.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>-20.165844</td>\n",
       "      <td>-20.351134</td>\n",
       "      <td>399</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>921</td>\n",
       "      <td>0.0131963</td>\n",
       "      <td>6.6380</td>\n",
       "      <td>0.0276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>-18.948420</td>\n",
       "      <td>-20.392704</td>\n",
       "      <td>1008</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>789</td>\n",
       "      <td>0.183354</td>\n",
       "      <td>17.9322</td>\n",
       "      <td>0.0646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>-18.794617</td>\n",
       "      <td>-20.413612</td>\n",
       "      <td>1280</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>595</td>\n",
       "      <td>0.106036</td>\n",
       "      <td>28.9990</td>\n",
       "      <td>0.0992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-18.671997</td>\n",
       "      <td>-20.423372</td>\n",
       "      <td>670</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>765</td>\n",
       "      <td>0.15897</td>\n",
       "      <td>17.3268</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-18.620826</td>\n",
       "      <td>-20.441570</td>\n",
       "      <td>774</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>202</td>\n",
       "      <td>0.237425</td>\n",
       "      <td>13.6896</td>\n",
       "      <td>0.0494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-18.553006</td>\n",
       "      <td>-20.457949</td>\n",
       "      <td>1106</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>656</td>\n",
       "      <td>0.0783331</td>\n",
       "      <td>36.3144</td>\n",
       "      <td>0.1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>-18.605304</td>\n",
       "      <td>-20.472518</td>\n",
       "      <td>469</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>368</td>\n",
       "      <td>0.246482</td>\n",
       "      <td>11.1846</td>\n",
       "      <td>0.0382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-18.425444</td>\n",
       "      <td>-20.495759</td>\n",
       "      <td>1053</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>762</td>\n",
       "      <td>0.0803784</td>\n",
       "      <td>36.0572</td>\n",
       "      <td>0.1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-18.376708</td>\n",
       "      <td>-20.514838</td>\n",
       "      <td>1426</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>995</td>\n",
       "      <td>0.08589</td>\n",
       "      <td>45.6874</td>\n",
       "      <td>0.1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>-18.466632</td>\n",
       "      <td>-20.522247</td>\n",
       "      <td>645</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>390</td>\n",
       "      <td>0.19701</td>\n",
       "      <td>15.4076</td>\n",
       "      <td>0.0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>-18.528103</td>\n",
       "      <td>-20.538455</td>\n",
       "      <td>773</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>472</td>\n",
       "      <td>0.295201</td>\n",
       "      <td>15.8622</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>-18.119661</td>\n",
       "      <td>-20.624226</td>\n",
       "      <td>1013</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>778</td>\n",
       "      <td>0.179854</td>\n",
       "      <td>30.4730</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>-18.121168</td>\n",
       "      <td>-20.642349</td>\n",
       "      <td>515</td>\n",
       "      <td>8</td>\n",
       "      <td>79</td>\n",
       "      <td>436</td>\n",
       "      <td>0.234279</td>\n",
       "      <td>17.1814</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>-18.070508</td>\n",
       "      <td>-20.643925</td>\n",
       "      <td>934</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>598</td>\n",
       "      <td>0.19208</td>\n",
       "      <td>29.6168</td>\n",
       "      <td>0.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>-17.882143</td>\n",
       "      <td>-20.725776</td>\n",
       "      <td>1323</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>423</td>\n",
       "      <td>0.165575</td>\n",
       "      <td>40.4942</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>-17.896276</td>\n",
       "      <td>-20.733363</td>\n",
       "      <td>1288</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>761</td>\n",
       "      <td>0.289966</td>\n",
       "      <td>34.7988</td>\n",
       "      <td>0.1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>-17.738236</td>\n",
       "      <td>-20.760502</td>\n",
       "      <td>1221</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>981</td>\n",
       "      <td>0.264187</td>\n",
       "      <td>36.5644</td>\n",
       "      <td>0.1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>-17.593651</td>\n",
       "      <td>-20.832448</td>\n",
       "      <td>1089</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>361</td>\n",
       "      <td>0.14283</td>\n",
       "      <td>41.6052</td>\n",
       "      <td>0.1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>-17.617484</td>\n",
       "      <td>-20.868276</td>\n",
       "      <td>936</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>281</td>\n",
       "      <td>0.173564</td>\n",
       "      <td>29.5086</td>\n",
       "      <td>0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>-17.316434</td>\n",
       "      <td>-21.066217</td>\n",
       "      <td>1450</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>220</td>\n",
       "      <td>0.30663</td>\n",
       "      <td>41.5088</td>\n",
       "      <td>0.1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_train_score  mean_test_score param_n_estimators  \\\n",
       "0                 1        -19.643172       -20.219603                 97   \n",
       "1                 2        -19.622397       -20.225150                278   \n",
       "2                 3        -19.488935       -20.241858                972   \n",
       "3                 4        -19.575668       -20.242302                 92   \n",
       "4                 5        -19.756980       -20.247097                130   \n",
       "5                 6        -19.397209       -20.247649                139   \n",
       "6                 7        -19.195216       -20.273595               1384   \n",
       "7                 8        -19.451504       -20.273762               1364   \n",
       "8                 9        -19.314743       -20.275938                242   \n",
       "9                10        -19.197217       -20.278124                179   \n",
       "10               11        -19.283857       -20.279669                912   \n",
       "11               12        -19.587199       -20.289760               1132   \n",
       "12               13        -19.632172       -20.297671               1406   \n",
       "13               14        -19.253388       -20.304629                995   \n",
       "14               15        -19.365190       -20.311878                876   \n",
       "15               16        -19.153522       -20.323321                211   \n",
       "16               17        -19.363450       -20.328112                672   \n",
       "17               18        -18.970964       -20.342355                877   \n",
       "18               19        -20.165844       -20.351134                399   \n",
       "19               20        -18.948420       -20.392704               1008   \n",
       "20               21        -18.794617       -20.413612               1280   \n",
       "21               22        -18.671997       -20.423372                670   \n",
       "22               23        -18.620826       -20.441570                774   \n",
       "23               24        -18.553006       -20.457949               1106   \n",
       "24               25        -18.605304       -20.472518                469   \n",
       "25               26        -18.425444       -20.495759               1053   \n",
       "26               27        -18.376708       -20.514838               1426   \n",
       "27               28        -18.466632       -20.522247                645   \n",
       "28               29        -18.528103       -20.538455                773   \n",
       "29               30        -18.119661       -20.624226               1013   \n",
       "30               31        -18.121168       -20.642349                515   \n",
       "31               32        -18.070508       -20.643925                934   \n",
       "32               33        -17.882143       -20.725776               1323   \n",
       "33               34        -17.896276       -20.733363               1288   \n",
       "34               35        -17.738236       -20.760502               1221   \n",
       "35               36        -17.593651       -20.832448               1089   \n",
       "36               37        -17.617484       -20.868276                936   \n",
       "37               38        -17.316434       -21.066217               1450   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "0                9                     87                     690   \n",
       "1                7                     79                     591   \n",
       "2                5                     46                     725   \n",
       "3                7                     85                     927   \n",
       "4                4                     57                     402   \n",
       "5                7                     37                     816   \n",
       "6                6                     23                     809   \n",
       "7                3                     21                     643   \n",
       "8                7                     73                     474   \n",
       "9                5                     34                     397   \n",
       "10               8                     65                     833   \n",
       "11               3                     70                     746   \n",
       "12               3                     85                     470   \n",
       "13               5                     97                     390   \n",
       "14               3                     44                     280   \n",
       "15               6                     46                     738   \n",
       "16               4                     85                     962   \n",
       "17               6                     11                     845   \n",
       "18               5                      8                     921   \n",
       "19               5                     23                     789   \n",
       "20               6                     96                     595   \n",
       "21               7                     37                     765   \n",
       "22               5                      7                     202   \n",
       "23               9                     88                     656   \n",
       "24               6                     94                     368   \n",
       "25               9                     33                     762   \n",
       "26               9                     36                     995   \n",
       "27               6                     53                     390   \n",
       "28               5                     60                     472   \n",
       "29               8                     68                     778   \n",
       "30               8                     79                     436   \n",
       "31               8                     90                     598   \n",
       "32               7                     72                     423   \n",
       "33               7                     93                     761   \n",
       "34               8                     58                     981   \n",
       "35               9                     60                     361   \n",
       "36               7                     24                     281   \n",
       "37               6                     58                     220   \n",
       "\n",
       "   param_learning_rate  mean_fit_time  mean_score_time  \n",
       "0             0.096419         2.8340           0.0118  \n",
       "1            0.0474928         6.6460           0.0256  \n",
       "2            0.0474484        15.6568           0.0592  \n",
       "3             0.261858         2.0752           0.0088  \n",
       "4             0.152155         1.8074           0.0078  \n",
       "5             0.196402         3.1310           0.0138  \n",
       "6            0.0505795        27.6146           0.1010  \n",
       "7             0.272337        14.4116           0.0560  \n",
       "8              0.10264         6.1448           0.0236  \n",
       "9             0.255524         3.1208           0.0120  \n",
       "10           0.0369084        23.8568           0.0868  \n",
       "11            0.205171        11.7122           0.0460  \n",
       "12            0.134782        15.1524           0.0582  \n",
       "13            0.070252        17.7686           0.0642  \n",
       "14            0.289916         9.6548           0.0406  \n",
       "15            0.292026         4.2512           0.0160  \n",
       "16            0.294354         8.7104           0.0346  \n",
       "17            0.134671        17.9388           0.0650  \n",
       "18           0.0131963         6.6380           0.0276  \n",
       "19            0.183354        17.9322           0.0646  \n",
       "20            0.106036        28.9990           0.0992  \n",
       "21             0.15897        17.3268           0.0598  \n",
       "22            0.237425        13.6896           0.0494  \n",
       "23           0.0783331        36.3144           0.1308  \n",
       "24            0.246482        11.1846           0.0382  \n",
       "25           0.0803784        36.0572           0.1198  \n",
       "26             0.08589        45.6874           0.1526  \n",
       "27             0.19701        15.4076           0.0510  \n",
       "28            0.295201        15.8622           0.0574  \n",
       "29            0.179854        30.4730           0.1014  \n",
       "30            0.234279        17.1814           0.0578  \n",
       "31             0.19208        29.6168           0.0964  \n",
       "32            0.165575        40.4942           0.1266  \n",
       "33            0.289966        34.7988           0.1174  \n",
       "34            0.264187        36.5644           0.1204  \n",
       "35             0.14283        41.6052           0.1288  \n",
       "36            0.173564        29.5086           0.0900  \n",
       "37             0.30663        41.5088           0.1272  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_learning_rate', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of best model on the test set is 0.105222009776\n",
      "\n",
      "Mean absolute error of best model on the test set is 20.0631847197\n",
      "Mean absolute percentage error of best model on the test set is 48.935%\n",
      "\n",
      "Median absolute error of best model on the test set is 17.9497498657\n",
      "Median absolute percentage error of best model on the test set is 43.78%\n",
      "time: 36 ms\n"
     ]
    }
   ],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with R-squared value as scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(75, 1500),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(5, 100),\n",
    "            'min_samples_split': stats.randint(200, 1000),\n",
    "            'learning_rate': stats.uniform(0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000000029FBC00, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\CS\\\\Anac...us\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000000029FBC00, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\CS\\\\Anac...us\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 22, 2, 12, 27, 858000, tzinfo=tzlocal()), 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'session': 'F1907572BEA64B59B54558C63F13C11F', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'F1907572BEA64B59B54558C63F13C11F']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 22, 2, 12, 27, 858000, tzinfo=tzlocal()), 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'session': 'F1907572BEA64B59B54558C63F13C11F', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'F1907572BEA64B59B54558C63F13C11F'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 22, 2, 12, 27, 858000, tzinfo=tzlocal()), 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'session': 'F1907572BEA64B59B54558C63F13C11F', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-93-792103d396a6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 68eb898, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000000006A0DE40, file \"<ipython-input-93-792103d396a6>\", line 2>\n        result = <ExecutionResult object at 68eb898, execution_co..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000000006A0DE40, file \"<ipython-input-93-792103d396a6>\", line 2>, result=<ExecutionResult object at 68eb898, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000000006A0DE40, file \"<ipython-input-93-792103d396a6>\", line 2>\n        self.user_global_ns = {'Day_dummies':        Day_Monday  Day_Saturday  Day_Sunday  Day...\n25226              1  \n\n[25227 rows x 6 columns], 'GBR': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'HF_dummies':        HF_6  HF_7  HF_8  HF_9  HF_10  HF_11  HF_...     0      0      0  \n\n[25227 rows x 18 columns], 'In': ['', '# setting variables\\n\\ncores = 3 # enter the numbe... the number of randomised search iterations here ', 'import pandas as pd\\nimport numpy as np\\nimport ma...xport_graphviz\\n#from IPython.display import Image', \"# Read in stop_times.txt and trips.txt files fro...csv' % r)\\n    res = pd.concat([df, res], axis=0) \", \"# create dataframe for SSIDno\\n\\nres['SSID'] = res..._df = ssid_df.drop('index', axis=1)\\nssid_df.shape\", 'JPID_Count = ssid_df.JourneyPatternID.unique().s... over the course of\", Row_Count, \"observations.\")', '# add leading zeroes to JourneyPatternID\\n\\nssid_d...JourneyPatternID.apply(lambda x: str(x).zfill(8))', \"# adding Xbuses feature - boolean feature indica...id_df['XBuses'] = ssid_df['XBuses'].astype('int')\", \"# adding JPID_length feature - represents the to...ternID')\\nssid_df = ssid_df.dropna()\\nssid_df.shape\", \"# removing non-holiday-period weekends from Scho...'2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)\", \"# dropping unneeded columns\\n\\nssid_df = ssid_df.d..., 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]\", \"# assigning appropriate datatypes where necessar...D_length'] = ssid_df['JPID_length'].astype('int')\", '# removing any constant features\\n# code from: ht...d_df.loc[:,ssid_df.apply(pd.Series.nunique) != 1]', 'ssid_df', 'ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)', \"ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)\", '# Checking stats for TravelTime\\n\\nssid_df.TravelTime.describe()', \"# loading table of minimum times to traverse seg...b['SSID'] == SSIDno, 'min_sec'].iloc[0]\\nprint(lb)\", '# make a copy of original df\\n\\ntrimssid_df = ssid...ere will be\", Outlier_Count, \"outliers dropped.\")', \"# dropping outliers\\n\\ntrimssid_df = trimssid_df[t...)\\ntrimssid_df = trimssid_df.drop('index', axis=1)\", ...], 'JPIDL':     JourneyPatternID  JPID_length\n0           00...    00091002           37\n\n[478 rows x 2 columns], 'JPID_Count': 38, 'LinR': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {4: (25259, 12), 8: (25259, 14), 13:        TravelTime      Rain  WindSpeed  JPID_len... 18  \n25258         8  \n\n[25259 rows x 7 columns], 14: <matplotlib.axes._subplots.AxesSubplot object>, 15: <matplotlib.axes._subplots.AxesSubplot object>, 16: count    25259.000000\nmean        47.010491\nstd ...      402.000000\nName: TravelTime, dtype: float64, 20: count    25227.000000\nmean        46.969794\nstd ...      179.000000\nName: TravelTime, dtype: float64, 21: <matplotlib.axes._subplots.AxesSubplot object>, 22: <matplotlib.axes._subplots.AxesSubplot object>, 23: [<matplotlib.lines.Line2D object>], ...}, 'Outlier_Count': 32, 'RSCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'Day_dummies':        Day_Monday  Day_Saturday  Day_Sunday  Day...\n25226              1  \n\n[25227 rows x 6 columns], 'GBR': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'HF_dummies':        HF_6  HF_7  HF_8  HF_9  HF_10  HF_11  HF_...     0      0      0  \n\n[25227 rows x 18 columns], 'In': ['', '# setting variables\\n\\ncores = 3 # enter the numbe... the number of randomised search iterations here ', 'import pandas as pd\\nimport numpy as np\\nimport ma...xport_graphviz\\n#from IPython.display import Image', \"# Read in stop_times.txt and trips.txt files fro...csv' % r)\\n    res = pd.concat([df, res], axis=0) \", \"# create dataframe for SSIDno\\n\\nres['SSID'] = res..._df = ssid_df.drop('index', axis=1)\\nssid_df.shape\", 'JPID_Count = ssid_df.JourneyPatternID.unique().s... over the course of\", Row_Count, \"observations.\")', '# add leading zeroes to JourneyPatternID\\n\\nssid_d...JourneyPatternID.apply(lambda x: str(x).zfill(8))', \"# adding Xbuses feature - boolean feature indica...id_df['XBuses'] = ssid_df['XBuses'].astype('int')\", \"# adding JPID_length feature - represents the to...ternID')\\nssid_df = ssid_df.dropna()\\nssid_df.shape\", \"# removing non-holiday-period weekends from Scho...'2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)\", \"# dropping unneeded columns\\n\\nssid_df = ssid_df.d..., 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]\", \"# assigning appropriate datatypes where necessar...D_length'] = ssid_df['JPID_length'].astype('int')\", '# removing any constant features\\n# code from: ht...d_df.loc[:,ssid_df.apply(pd.Series.nunique) != 1]', 'ssid_df', 'ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)', \"ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)\", '# Checking stats for TravelTime\\n\\nssid_df.TravelTime.describe()', \"# loading table of minimum times to traverse seg...b['SSID'] == SSIDno, 'min_sec'].iloc[0]\\nprint(lb)\", '# make a copy of original df\\n\\ntrimssid_df = ssid...ere will be\", Outlier_Count, \"outliers dropped.\")', \"# dropping outliers\\n\\ntrimssid_df = trimssid_df[t...)\\ntrimssid_df = trimssid_df.drop('index', axis=1)\", ...], 'JPIDL':     JourneyPatternID  JPID_length\n0           00...    00091002           37\n\n[478 rows x 2 columns], 'JPID_Count': 38, 'LinR': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {4: (25259, 12), 8: (25259, 14), 13:        TravelTime      Rain  WindSpeed  JPID_len... 18  \n25258         8  \n\n[25259 rows x 7 columns], 14: <matplotlib.axes._subplots.AxesSubplot object>, 15: <matplotlib.axes._subplots.AxesSubplot object>, 16: count    25259.000000\nmean        47.010491\nstd ...      402.000000\nName: TravelTime, dtype: float64, 20: count    25227.000000\nmean        46.969794\nstd ...      179.000000\nName: TravelTime, dtype: float64, 21: <matplotlib.axes._subplots.AxesSubplot object>, 22: <matplotlib.axes._subplots.AxesSubplot object>, 23: [<matplotlib.lines.Line2D object>], ...}, 'Outlier_Count': 32, 'RSCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nD:\\HDipCS\\COMP47360_Research_Practicum\\SSID time output\\<ipython-input-93-792103d396a6> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.r2_score))\n      6 gbr_rsearch.fit(X_train, y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...oring=make_scorer(r2_score),\n          verbose=0), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...ring=make_scorer(r2_score),\n          verbose=0)>\n        X =            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns]\n        y = 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_search.py in _fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...oring=make_scorer(r2_score),\n          verbose=0), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Aug 22 02:12:28 2017\nPID: 3632            Python 3.6.1: C:\\CS\\Anaconda\\envs\\DublinBus\\python.exe\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, scorer=make_scorer(r2_score), train=array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), test=array([   0,    1,    2, ..., 3529, 3530, 3531]), verbose=0, parameters={'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...e=1.0, verbose=0,\n             warm_start=False)>\n        X_train =            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[14126 rows x 28 columns]\n        y_train = 4123      80\n660      101\n14611     39\n10154    ... 20\nName: TravelTime, Length: 14126, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in fit(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), monitor=None)\n   1023                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1024                                                  dtype=np.int32)\n   1025 \n   1026         # fit the boosting stages\n   1027         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1028                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1029         # change shape of arrays after fit (early-stopping or additional ests)\n   1030         if n_stages != self.estimators_.shape[0]:\n   1031             self.estimators_ = self.estimators_[:n_stages]\n   1032             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stages(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1078                                       sample_weight[~sample_mask])\n   1079 \n   1080             # fit next stage of trees\n   1081             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1082                                      sample_mask, random_state, X_idx_sorted,\n-> 1083                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1084 \n   1085             # track deviance (= loss)\n   1086             if do_oob:\n   1087                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stage(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), i=0, X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), sample_mask=array([ True,  True,  True, ...,  True,  True,  True], dtype=bool), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]), X_csc=None, X_csr=None)\n    782             if X_csc is not None:\n    783                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    784                          check_input=False, X_idx_sorted=X_idx_sorted)\n    785             else:\n    786                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 787                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n    788 \n    789             # update tree leaves\n    790             if X_csr is not None:\n    791                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 39.,  41.,  -2., ...,  38.,  -2., -21.]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([[ 39.],\n       [ 41.],\n       [ -2.],\n   ...., \n       [ 38.],\n       [ -2.],\n       [-21.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n    204                                  \"or in (0, 1], got %s\"\n--> 205                                  % self.min_samples_split)\n        self.min_samples_split = 1.3428354021176023\n    206             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n    207             min_samples_split = max(2, min_samples_split)\n    208 \n    209         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1.34283540212\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\", line 1028, in fit\n    begin_at_stage, monitor, X_idx_sorted)\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\", line 1083, in _fit_stages\n    X_csc, X_csr)\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\", line 787, in _fit_stage\n    check_input=False, X_idx_sorted=X_idx_sorted)\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 1029, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 205, in fit\n    % self.min_samples_split)\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1.34283540212\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Aug 22 02:12:28 2017\nPID: 3632            Python 3.6.1: C:\\CS\\Anaconda\\envs\\DublinBus\\python.exe\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, scorer=make_scorer(r2_score), train=array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), test=array([   0,    1,    2, ..., 3529, 3530, 3531]), verbose=0, parameters={'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...e=1.0, verbose=0,\n             warm_start=False)>\n        X_train =            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[14126 rows x 28 columns]\n        y_train = 4123      80\n660      101\n14611     39\n10154    ... 20\nName: TravelTime, Length: 14126, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in fit(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), monitor=None)\n   1023                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1024                                                  dtype=np.int32)\n   1025 \n   1026         # fit the boosting stages\n   1027         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1028                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1029         # change shape of arrays after fit (early-stopping or additional ests)\n   1030         if n_stages != self.estimators_.shape[0]:\n   1031             self.estimators_ = self.estimators_[:n_stages]\n   1032             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stages(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1078                                       sample_weight[~sample_mask])\n   1079 \n   1080             # fit next stage of trees\n   1081             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1082                                      sample_mask, random_state, X_idx_sorted,\n-> 1083                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1084 \n   1085             # track deviance (= loss)\n   1086             if do_oob:\n   1087                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stage(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), i=0, X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), sample_mask=array([ True,  True,  True, ...,  True,  True,  True], dtype=bool), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]), X_csc=None, X_csr=None)\n    782             if X_csc is not None:\n    783                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    784                          check_input=False, X_idx_sorted=X_idx_sorted)\n    785             else:\n    786                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 787                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n    788 \n    789             # update tree leaves\n    790             if X_csr is not None:\n    791                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 39.,  41.,  -2., ...,  38.,  -2., -21.]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([[ 39.],\n       [ 41.],\n       [ -2.],\n   ...., \n       [ 38.],\n       [ -2.],\n       [-21.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n    204                                  \"or in (0, 1], got %s\"\n--> 205                                  % self.min_samples_split)\n        self.min_samples_split = 1.3428354021176023\n    206             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n    207             min_samples_split = max(2, min_samples_split)\n    208 \n    209         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1.34283540212\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Aug 22 02:12:28 2017\nPID: 3632            Python 3.6.1: C:\\CS\\Anaconda\\envs\\DublinBus\\python.exe\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, scorer=make_scorer(r2_score), train=array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), test=array([   0,    1,    2, ..., 3529, 3530, 3531]), verbose=0, parameters={'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...e=1.0, verbose=0,\n             warm_start=False)>\n        X_train =            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[14126 rows x 28 columns]\n        y_train = 4123      80\n660      101\n14611     39\n10154    ... 20\nName: TravelTime, Length: 14126, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in fit(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), monitor=None)\n   1023                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1024                                                  dtype=np.int32)\n   1025 \n   1026         # fit the boosting stages\n   1027         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1028                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1029         # change shape of arrays after fit (early-stopping or additional ests)\n   1030         if n_stages != self.estimators_.shape[0]:\n   1031             self.estimators_ = self.estimators_[:n_stages]\n   1032             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stages(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1078                                       sample_weight[~sample_mask])\n   1079 \n   1080             # fit next stage of trees\n   1081             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1082                                      sample_mask, random_state, X_idx_sorted,\n-> 1083                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1084 \n   1085             # track deviance (= loss)\n   1086             if do_oob:\n   1087                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stage(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), i=0, X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), sample_mask=array([ True,  True,  True, ...,  True,  True,  True], dtype=bool), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]), X_csc=None, X_csr=None)\n    782             if X_csc is not None:\n    783                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    784                          check_input=False, X_idx_sorted=X_idx_sorted)\n    785             else:\n    786                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 787                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n    788 \n    789             # update tree leaves\n    790             if X_csr is not None:\n    791                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 39.,  41.,  -2., ...,  38.,  -2., -21.]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([[ 39.],\n       [ 41.],\n       [ -2.],\n   ...., \n       [ 38.],\n       [ -2.],\n       [-21.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n    204                                  \"or in (0, 1], got %s\"\n--> 205                                  % self.min_samples_split)\n        self.min_samples_split = 1.3428354021176023\n    206             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n    207             min_samples_split = max(2, min_samples_split)\n    208 \n    209         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1.34283540212\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-792103d396a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgbr_rsearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRSCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_gbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgbr_rsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[1;32m-> 1190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m--> 564\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000000029FBC00, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\CS\\\\Anac...us\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000000029FBC00, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...Bus\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\CS\\\\Anac...us\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 22, 2, 12, 27, 858000, tzinfo=tzlocal()), 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'session': 'F1907572BEA64B59B54558C63F13C11F', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'F1907572BEA64B59B54558C63F13C11F']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 22, 2, 12, 27, 858000, tzinfo=tzlocal()), 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'session': 'F1907572BEA64B59B54558C63F13C11F', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'F1907572BEA64B59B54558C63F13C11F'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 22, 2, 12, 27, 858000, tzinfo=tzlocal()), 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'session': 'F1907572BEA64B59B54558C63F13C11F', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C1F1EBD54D014EB689EA222BB62C70A5', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gbr_rsearch = RSCV(gbr, param_distributions=para...rics.r2_score))\\ngbr_rsearch.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-93-792103d396a6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 68eb898, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000000006A0DE40, file \"<ipython-input-93-792103d396a6>\", line 2>\n        result = <ExecutionResult object at 68eb898, execution_co..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000000006A0DE40, file \"<ipython-input-93-792103d396a6>\", line 2>, result=<ExecutionResult object at 68eb898, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000000006A0DE40, file \"<ipython-input-93-792103d396a6>\", line 2>\n        self.user_global_ns = {'Day_dummies':        Day_Monday  Day_Saturday  Day_Sunday  Day...\n25226              1  \n\n[25227 rows x 6 columns], 'GBR': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'HF_dummies':        HF_6  HF_7  HF_8  HF_9  HF_10  HF_11  HF_...     0      0      0  \n\n[25227 rows x 18 columns], 'In': ['', '# setting variables\\n\\ncores = 3 # enter the numbe... the number of randomised search iterations here ', 'import pandas as pd\\nimport numpy as np\\nimport ma...xport_graphviz\\n#from IPython.display import Image', \"# Read in stop_times.txt and trips.txt files fro...csv' % r)\\n    res = pd.concat([df, res], axis=0) \", \"# create dataframe for SSIDno\\n\\nres['SSID'] = res..._df = ssid_df.drop('index', axis=1)\\nssid_df.shape\", 'JPID_Count = ssid_df.JourneyPatternID.unique().s... over the course of\", Row_Count, \"observations.\")', '# add leading zeroes to JourneyPatternID\\n\\nssid_d...JourneyPatternID.apply(lambda x: str(x).zfill(8))', \"# adding Xbuses feature - boolean feature indica...id_df['XBuses'] = ssid_df['XBuses'].astype('int')\", \"# adding JPID_length feature - represents the to...ternID')\\nssid_df = ssid_df.dropna()\\nssid_df.shape\", \"# removing non-holiday-period weekends from Scho...'2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)\", \"# dropping unneeded columns\\n\\nssid_df = ssid_df.d..., 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]\", \"# assigning appropriate datatypes where necessar...D_length'] = ssid_df['JPID_length'].astype('int')\", '# removing any constant features\\n# code from: ht...d_df.loc[:,ssid_df.apply(pd.Series.nunique) != 1]', 'ssid_df', 'ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)', \"ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)\", '# Checking stats for TravelTime\\n\\nssid_df.TravelTime.describe()', \"# loading table of minimum times to traverse seg...b['SSID'] == SSIDno, 'min_sec'].iloc[0]\\nprint(lb)\", '# make a copy of original df\\n\\ntrimssid_df = ssid...ere will be\", Outlier_Count, \"outliers dropped.\")', \"# dropping outliers\\n\\ntrimssid_df = trimssid_df[t...)\\ntrimssid_df = trimssid_df.drop('index', axis=1)\", ...], 'JPIDL':     JourneyPatternID  JPID_length\n0           00...    00091002           37\n\n[478 rows x 2 columns], 'JPID_Count': 38, 'LinR': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {4: (25259, 12), 8: (25259, 14), 13:        TravelTime      Rain  WindSpeed  JPID_len... 18  \n25258         8  \n\n[25259 rows x 7 columns], 14: <matplotlib.axes._subplots.AxesSubplot object>, 15: <matplotlib.axes._subplots.AxesSubplot object>, 16: count    25259.000000\nmean        47.010491\nstd ...      402.000000\nName: TravelTime, dtype: float64, 20: count    25227.000000\nmean        46.969794\nstd ...      179.000000\nName: TravelTime, dtype: float64, 21: <matplotlib.axes._subplots.AxesSubplot object>, 22: <matplotlib.axes._subplots.AxesSubplot object>, 23: [<matplotlib.lines.Line2D object>], ...}, 'Outlier_Count': 32, 'RSCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'Day_dummies':        Day_Monday  Day_Saturday  Day_Sunday  Day...\n25226              1  \n\n[25227 rows x 6 columns], 'GBR': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>, 'HF_dummies':        HF_6  HF_7  HF_8  HF_9  HF_10  HF_11  HF_...     0      0      0  \n\n[25227 rows x 18 columns], 'In': ['', '# setting variables\\n\\ncores = 3 # enter the numbe... the number of randomised search iterations here ', 'import pandas as pd\\nimport numpy as np\\nimport ma...xport_graphviz\\n#from IPython.display import Image', \"# Read in stop_times.txt and trips.txt files fro...csv' % r)\\n    res = pd.concat([df, res], axis=0) \", \"# create dataframe for SSIDno\\n\\nres['SSID'] = res..._df = ssid_df.drop('index', axis=1)\\nssid_df.shape\", 'JPID_Count = ssid_df.JourneyPatternID.unique().s... over the course of\", Row_Count, \"observations.\")', '# add leading zeroes to JourneyPatternID\\n\\nssid_d...JourneyPatternID.apply(lambda x: str(x).zfill(8))', \"# adding Xbuses feature - boolean feature indica...id_df['XBuses'] = ssid_df['XBuses'].astype('int')\", \"# adding JPID_length feature - represents the to...ternID')\\nssid_df = ssid_df.dropna()\\nssid_df.shape\", \"# removing non-holiday-period weekends from Scho...'2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)\", \"# dropping unneeded columns\\n\\nssid_df = ssid_df.d..., 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]\", \"# assigning appropriate datatypes where necessar...D_length'] = ssid_df['JPID_length'].astype('int')\", '# removing any constant features\\n# code from: ht...d_df.loc[:,ssid_df.apply(pd.Series.nunique) != 1]', 'ssid_df', 'ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)', \"ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)\", '# Checking stats for TravelTime\\n\\nssid_df.TravelTime.describe()', \"# loading table of minimum times to traverse seg...b['SSID'] == SSIDno, 'min_sec'].iloc[0]\\nprint(lb)\", '# make a copy of original df\\n\\ntrimssid_df = ssid...ere will be\", Outlier_Count, \"outliers dropped.\")', \"# dropping outliers\\n\\ntrimssid_df = trimssid_df[t...)\\ntrimssid_df = trimssid_df.drop('index', axis=1)\", ...], 'JPIDL':     JourneyPatternID  JPID_length\n0           00...    00091002           37\n\n[478 rows x 2 columns], 'JPID_Count': 38, 'LinR': <class 'sklearn.linear_model.base.LinearRegression'>, 'Out': {4: (25259, 12), 8: (25259, 14), 13:        TravelTime      Rain  WindSpeed  JPID_len... 18  \n25258         8  \n\n[25259 rows x 7 columns], 14: <matplotlib.axes._subplots.AxesSubplot object>, 15: <matplotlib.axes._subplots.AxesSubplot object>, 16: count    25259.000000\nmean        47.010491\nstd ...      402.000000\nName: TravelTime, dtype: float64, 20: count    25227.000000\nmean        46.969794\nstd ...      179.000000\nName: TravelTime, dtype: float64, 21: <matplotlib.axes._subplots.AxesSubplot object>, 22: <matplotlib.axes._subplots.AxesSubplot object>, 23: [<matplotlib.lines.Line2D object>], ...}, 'Outlier_Count': 32, 'RSCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nD:\\HDipCS\\COMP47360_Research_Practicum\\SSID time output\\<ipython-input-93-792103d396a6> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.r2_score))\n      6 gbr_rsearch.fit(X_train, y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...oring=make_scorer(r2_score),\n          verbose=0), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, groups=None)\n   1185             train/test set.\n   1186         \"\"\"\n   1187         sampled_params = ParameterSampler(self.param_distributions,\n   1188                                           self.n_iter,\n   1189                                           random_state=self.random_state)\n-> 1190         return self._fit(X, y, groups, sampled_params)\n        self._fit = <bound method BaseSearchCV._fit of RandomizedSea...ring=make_scorer(r2_score),\n          verbose=0)>\n        X =            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns]\n        y = 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64\n        groups = None\n        sampled_params = <sklearn.model_selection._search.ParameterSampler object>\n   1191 \n   1192 \n   1193 \n   1194 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_search.py in _fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...oring=make_scorer(r2_score),\n          verbose=0), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterSampler object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterSampler object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Aug 22 02:12:28 2017\nPID: 3632            Python 3.6.1: C:\\CS\\Anaconda\\envs\\DublinBus\\python.exe\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False),            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], 16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, make_scorer(r2_score), array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), array([   0,    1,    2, ..., 3529, 3530, 3531]), 0, {'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=           Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[17658 rows x 28 columns], y=16400     37\n6957      60\n5792      63\n5459     ... 20\nName: TravelTime, Length: 17658, dtype: int64, scorer=make_scorer(r2_score), train=array([ 3532,  3533,  3534, ..., 17655, 17656, 17657]), test=array([   0,    1,    2, ..., 3529, 3530, 3531]), verbose=0, parameters={'learning_rate': 0.066007332885851477, 'max_depth': 7, 'min_samples_leaf': 27, 'min_samples_split': 1.3428354021176023, 'n_estimators': 1075}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...e=1.0, verbose=0,\n             warm_start=False)>\n        X_train =            Rain  WindSpeed  JPID_length  SchoolH...20533              0  \n\n[14126 rows x 28 columns]\n        y_train = 4123      80\n660      101\n14611     39\n10154    ... 20\nName: TravelTime, Length: 14126, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in fit(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), monitor=None)\n   1023                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1024                                                  dtype=np.int32)\n   1025 \n   1026         # fit the boosting stages\n   1027         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1028                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1029         # change shape of arrays after fit (early-stopping or additional ests)\n   1030         if n_stages != self.estimators_.shape[0]:\n   1031             self.estimators_ = self.estimators_[:n_stages]\n   1032             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stages(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1078                                       sample_weight[~sample_mask])\n   1079 \n   1080             # fit next stage of trees\n   1081             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1082                                      sample_mask, random_state, X_idx_sorted,\n-> 1083                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1084 \n   1085             # track deviance (= loss)\n   1086             if do_oob:\n   1087                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py in _fit_stage(self=GradientBoostingRegressor(alpha=0.9, criterion='...le=1.0, verbose=0,\n             warm_start=False), i=0, X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 80, 101,  39, ...,  79,  39,  20], dtype=int64), y_pred=array([[ 41.],\n       [ 41.],\n       [ 41.],\n   ...., \n       [ 41.],\n       [ 41.],\n       [ 41.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), sample_mask=array([ True,  True,  True, ...,  True,  True,  True], dtype=bool), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]), X_csc=None, X_csr=None)\n    782             if X_csc is not None:\n    783                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    784                          check_input=False, X_idx_sorted=X_idx_sorted)\n    785             else:\n    786                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 787                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n    788 \n    789             # update tree leaves\n    790             if X_csr is not None:\n    791                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([ 39.,  41.,  -2., ...,  38.,  -2., -21.]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]])\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\nC:\\CS\\Anaconda\\envs\\DublinBus\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ... 0x0000000003883798>,\n           splitter='best'), X=array([[  0. ,   4. ,  53. , ...,   1. ,   0. , ... 93. , ...,   0. ,   0. ,   0. ]], dtype=float32), y=array([[ 39.],\n       [ 41.],\n       [ -2.],\n   ...., \n       [ 38.],\n       [ -2.],\n       [-21.]]), sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32), check_input=False, X_idx_sorted=array([[    0, 11142, 10458, ...,  7062,     0, ...[ 1485,  9133,  6332, ...,     0,  2134,  7062]]))\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n    204                                  \"or in (0, 1], got %s\"\n--> 205                                  % self.min_samples_split)\n        self.min_samples_split = 1.3428354021176023\n    206             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n    207             min_samples_split = max(2, min_samples_split)\n    208 \n    209         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1.34283540212\n___________________________________________________________________________"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.r2_score))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_train_rsqa = abs(gbr_rsearch.best_score_)\n",
    "\n",
    "print(\"Best R-squared value found is\", gbr_train_rsqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_learning_rate', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b Gradient Boosting with new parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "mss = int(Row_Count/100)\n",
    "gbr = GBR(loss='huber', min_samples_split = mss)\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(50, 300),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(1, 75),\n",
    "            'learning_rate': stats.uniform(0.001, 0.1),\n",
    "            'subsample': [0.6, 0.7, 0.8, 0.9]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='huber', max_depth=3,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=252, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=38, n_jobs=3,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000006994AC8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000006994160>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000006994438>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000006994898>, 'subsample': [0.6, 0.7, 0.8, 0.9]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True,\n",
       "          scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5min 16s\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.mean_absolute_error, greater_is_better=False))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found:\n",
      "{'learning_rate': 0.039714888443438193, 'max_depth': 6, 'min_samples_leaf': 5, 'n_estimators': 245, 'subsample': 0.8}\n",
      "time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean absolute error found is 20.1849340049\n",
      "Best Mean absolute percentage error found is 43.466%\n",
      "time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_train_MAE = abs(gbr_rsearch.best_score_)\n",
    "gbr_train_MAPE = (gbr_train_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"Best Mean absolute error found is\", gbr_train_MAE)\n",
    "print (\"Best Mean absolute percentage error found is\", str(round(gbr_train_MAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full ranked results for GBR RandomizedSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-19.494784</td>\n",
       "      <td>-20.184934</td>\n",
       "      <td>245</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0397149</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.9112</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-19.504154</td>\n",
       "      <td>-20.190350</td>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0215794</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.7848</td>\n",
       "      <td>0.0326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-19.556228</td>\n",
       "      <td>-20.192593</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0483931</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.0886</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-19.268544</td>\n",
       "      <td>-20.193660</td>\n",
       "      <td>291</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0290719</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.3770</td>\n",
       "      <td>0.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-19.375391</td>\n",
       "      <td>-20.194403</td>\n",
       "      <td>94</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0640658</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.3774</td>\n",
       "      <td>0.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-19.559122</td>\n",
       "      <td>-20.202818</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0452516</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.7486</td>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-19.178923</td>\n",
       "      <td>-20.204662</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0469576</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.7928</td>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-19.358782</td>\n",
       "      <td>-20.213276</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0488921</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.6116</td>\n",
       "      <td>0.0252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-19.737851</td>\n",
       "      <td>-20.219251</td>\n",
       "      <td>123</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0377216</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7368</td>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-19.674886</td>\n",
       "      <td>-20.221081</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0965988</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1546</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-19.223702</td>\n",
       "      <td>-20.223570</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0794358</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.2012</td>\n",
       "      <td>0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-19.591881</td>\n",
       "      <td>-20.225340</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7992</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>-19.680025</td>\n",
       "      <td>-20.232279</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0951071</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3316</td>\n",
       "      <td>0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-19.694150</td>\n",
       "      <td>-20.233292</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0949642</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8972</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-19.132312</td>\n",
       "      <td>-20.235107</td>\n",
       "      <td>294</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0427034</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.8666</td>\n",
       "      <td>0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-19.263892</td>\n",
       "      <td>-20.236296</td>\n",
       "      <td>273</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0643665</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5582</td>\n",
       "      <td>0.0232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-19.369303</td>\n",
       "      <td>-20.240463</td>\n",
       "      <td>136</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0947697</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7264</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>-19.885068</td>\n",
       "      <td>-20.249177</td>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0396479</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.2496</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>-19.261937</td>\n",
       "      <td>-20.249234</td>\n",
       "      <td>205</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0962218</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.0264</td>\n",
       "      <td>0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>-19.874782</td>\n",
       "      <td>-20.249371</td>\n",
       "      <td>248</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0434233</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.9098</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>-19.451664</td>\n",
       "      <td>-20.253890</td>\n",
       "      <td>151</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0993388</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6090</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>-19.446827</td>\n",
       "      <td>-20.258494</td>\n",
       "      <td>212</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0787853</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.9642</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-19.520304</td>\n",
       "      <td>-20.267039</td>\n",
       "      <td>221</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0690411</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0694</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-19.927896</td>\n",
       "      <td>-20.270878</td>\n",
       "      <td>167</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0195097</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.2032</td>\n",
       "      <td>0.0196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>-19.978775</td>\n",
       "      <td>-20.290074</td>\n",
       "      <td>220</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0197482</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.2116</td>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-20.003857</td>\n",
       "      <td>-20.293601</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0434679</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0008</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-20.004493</td>\n",
       "      <td>-20.313092</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0657375</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4766</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>-20.037421</td>\n",
       "      <td>-20.322196</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0317998</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.8880</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>-18.884538</td>\n",
       "      <td>-20.329082</td>\n",
       "      <td>215</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0969721</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.0740</td>\n",
       "      <td>0.0248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>-18.833497</td>\n",
       "      <td>-20.338045</td>\n",
       "      <td>264</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0677241</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.5688</td>\n",
       "      <td>0.0334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>-20.257344</td>\n",
       "      <td>-20.398731</td>\n",
       "      <td>219</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00552041</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.5506</td>\n",
       "      <td>0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>-20.220348</td>\n",
       "      <td>-20.400336</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0949924</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>-18.626253</td>\n",
       "      <td>-20.408505</td>\n",
       "      <td>291</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0932072</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9.7898</td>\n",
       "      <td>0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>-20.379183</td>\n",
       "      <td>-20.429701</td>\n",
       "      <td>254</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00130841</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.8938</td>\n",
       "      <td>0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>-20.298305</td>\n",
       "      <td>-20.447184</td>\n",
       "      <td>172</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0398914</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.1402</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>-20.304852</td>\n",
       "      <td>-20.463089</td>\n",
       "      <td>274</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00972892</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.5064</td>\n",
       "      <td>0.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>-20.501522</td>\n",
       "      <td>-20.581253</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0101906</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.6562</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>-20.482668</td>\n",
       "      <td>-20.587385</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0340075</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5090</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_train_score  mean_test_score param_n_estimators  \\\n",
       "0                 1        -19.494784       -20.184934                245   \n",
       "1                 2        -19.504154       -20.190350                248   \n",
       "2                 3        -19.556228       -20.192593                 88   \n",
       "3                 4        -19.268544       -20.193660                291   \n",
       "4                 5        -19.375391       -20.194403                 94   \n",
       "5                 6        -19.559122       -20.202818                127   \n",
       "6                 7        -19.178923       -20.204662                157   \n",
       "7                 8        -19.358782       -20.213276                170   \n",
       "8                 9        -19.737851       -20.219251                123   \n",
       "9                10        -19.674886       -20.221081                107   \n",
       "10               11        -19.223702       -20.223570                133   \n",
       "11               12        -19.591881       -20.225340                102   \n",
       "12               13        -19.680025       -20.232279                117   \n",
       "13               14        -19.694150       -20.233292                 58   \n",
       "14               15        -19.132312       -20.235107                294   \n",
       "15               16        -19.263892       -20.236296                273   \n",
       "16               17        -19.369303       -20.240463                136   \n",
       "17               18        -19.885068       -20.249177                268   \n",
       "18               19        -19.261937       -20.249234                205   \n",
       "19               20        -19.874782       -20.249371                248   \n",
       "20               21        -19.451664       -20.253890                151   \n",
       "21               22        -19.446827       -20.258494                212   \n",
       "22               23        -19.520304       -20.267039                221   \n",
       "23               24        -19.927896       -20.270878                167   \n",
       "24               25        -19.978775       -20.290074                220   \n",
       "25               26        -20.003857       -20.293601                188   \n",
       "26               27        -20.004493       -20.313092                 63   \n",
       "27               28        -20.037421       -20.322196                108   \n",
       "28               29        -18.884538       -20.329082                215   \n",
       "29               30        -18.833497       -20.338045                264   \n",
       "30               31        -20.257344       -20.398731                219   \n",
       "31               32        -20.220348       -20.400336                 51   \n",
       "32               33        -18.626253       -20.408505                291   \n",
       "33               34        -20.379183       -20.429701                254   \n",
       "34               35        -20.298305       -20.447184                172   \n",
       "35               36        -20.304852       -20.463089                274   \n",
       "36               37        -20.501522       -20.581253                133   \n",
       "37               38        -20.482668       -20.587385                125   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_learning_rate param_subsample  \\\n",
       "0                6                      5           0.0397149             0.8   \n",
       "1                9                     35           0.0215794             0.8   \n",
       "2                9                      3           0.0483931             0.7   \n",
       "3                8                     16           0.0290719             0.9   \n",
       "4                9                     17           0.0640658             0.8   \n",
       "5                8                      8           0.0452516             0.6   \n",
       "6                9                     10           0.0469576             0.9   \n",
       "7                9                     25           0.0488921             0.6   \n",
       "8                8                     44           0.0377216             0.7   \n",
       "9                5                      1           0.0965988             0.7   \n",
       "10               8                     34           0.0794358             0.9   \n",
       "11               7                     67            0.079321             0.9   \n",
       "12               5                     35           0.0951071             0.8   \n",
       "13               8                     62           0.0949642             0.8   \n",
       "14               8                      6           0.0427034             0.6   \n",
       "15               6                     16           0.0643665             0.7   \n",
       "16               7                     42           0.0947697             0.7   \n",
       "17               4                     30           0.0396479             0.8   \n",
       "18               6                     26           0.0962218             0.7   \n",
       "19               4                     32           0.0434233             0.8   \n",
       "20               6                     57           0.0993388             0.8   \n",
       "21               6                     42           0.0787853             0.6   \n",
       "22               6                     49           0.0690411             0.6   \n",
       "23               8                     58           0.0195097             0.8   \n",
       "24               6                     41           0.0197482             0.7   \n",
       "25               4                     39           0.0434679             0.8   \n",
       "26               6                     57           0.0657375             0.9   \n",
       "27               7                     72           0.0317998             0.8   \n",
       "28               8                     44           0.0969721             0.9   \n",
       "29               9                     43           0.0677241             0.9   \n",
       "30               8                     14          0.00552041             0.7   \n",
       "31               4                     28           0.0949924             0.6   \n",
       "32               8                     26           0.0932072             0.8   \n",
       "33               9                     21          0.00130841             0.8   \n",
       "34               3                     45           0.0398914             0.8   \n",
       "35               5                     22          0.00972892             0.8   \n",
       "36               5                     11           0.0101906             0.7   \n",
       "37               3                     17           0.0340075             0.8   \n",
       "\n",
       "    mean_fit_time  mean_score_time  \n",
       "0          5.9112           0.0210  \n",
       "1          8.7848           0.0326  \n",
       "2          3.0886           0.0120  \n",
       "3          9.3770           0.0336  \n",
       "4          3.3774           0.0128  \n",
       "5          3.7486           0.0144  \n",
       "6          5.7928           0.0208  \n",
       "7          5.6116           0.0252  \n",
       "8          3.7368           0.0144  \n",
       "9          2.1546           0.0080  \n",
       "10         4.2012           0.0156  \n",
       "11         2.7992           0.0108  \n",
       "12         2.3316           0.0088  \n",
       "13         1.8972           0.0078  \n",
       "14         8.8666           0.0330  \n",
       "15         6.5582           0.0232  \n",
       "16         3.7264           0.0138  \n",
       "17         4.2496           0.0154  \n",
       "18         5.0264           0.0180  \n",
       "19         3.9098           0.0150  \n",
       "20         3.6090           0.0130  \n",
       "21         4.9642           0.0198  \n",
       "22         5.0694           0.0190  \n",
       "23         5.2032           0.0196  \n",
       "24         5.2116           0.0208  \n",
       "25         3.0008           0.0112  \n",
       "26         1.4766           0.0060  \n",
       "27         2.8880           0.0114  \n",
       "28         7.0740           0.0248  \n",
       "29         9.5688           0.0334  \n",
       "30         6.5506           0.0266  \n",
       "31         0.8312           0.0038  \n",
       "32         9.7898           0.0330  \n",
       "33         8.8938           0.0344  \n",
       "34         2.1402           0.0084  \n",
       "35         5.5064           0.0192  \n",
       "36         2.6562           0.0102  \n",
       "37         1.5090           0.0060  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_learning_rate', 'param_subsample', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value of best model on the test set is 0.107462012332\n",
      "\n",
      "Mean absolute error of best model on the test set is 20.0342813235\n",
      "Mean absolute percentage error of best model on the test set is 48.864%\n",
      "\n",
      "Median absolute error of best model on the test set is 17.9950216512\n",
      "Median absolute percentage error of best model on the test set is 43.89%\n",
      "time: 57 ms\n"
     ]
    }
   ],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5a Gradient Boosting Regression model - training - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='huber', max_depth=5,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=126,\n",
       "             min_samples_split=252, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, presort='auto', random_state=None,\n",
       "             subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='huber', min_samples_split = mss, min_samples_leaf=int(mss/2), learning_rate=0.05, \n",
    "          n_estimators=300, max_depth=5, subsample=0.8)\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.137817832529\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 19.7661221344\n",
      "The mean absolute percentage error is 42.0826244663\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 17.7584686255\n",
      "The median absolute percentage error is 43.313338111\n",
      "time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5b Gradient Boosting Regression model - testing - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.103840157741\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 20.0991559061\n",
      "The mean absolute percentage error is 42.7916626404\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 18.011611789\n",
      "The median absolute percentage error is 43.9307604609\n",
      "time: 54 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='huber', max_depth=6,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=126,\n",
       "             min_samples_split=252, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=300, presort='auto', random_state=None,\n",
       "             subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "gbr = GBR(loss='huber', min_samples_split = int(Row_Count/100), min_samples_leaf=int(Row_Count/200), \n",
    "          learning_rate=0.1, n_estimators=300, max_depth=6, subsample=0.8)\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.164154783297\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 19.3989803744\n",
      "The mean absolute percentage error is 41.3009694351\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 17.126838151\n",
      "The median absolute percentage error is 41.7727759781\n",
      "time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5b Gradient Boosting Regression model - testing - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R-squared value of the trained Gradient Boosting Regression model is 0.099919130959\n",
      "\n",
      "The mean absolute error of the trained Gradient Boosting Regression model is 20.1114949824\n",
      "The mean absolute percentage error is 42.8179328775\n",
      "\n",
      "The median absolute error of the trained Gradient Boosting Regression model is 17.7675854585\n",
      "The median absolute percentage error is 43.3355742891\n",
      "time: 65 ms\n"
     ]
    }
   ],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DublinBus]",
   "language": "python",
   "name": "conda-env-DublinBus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
