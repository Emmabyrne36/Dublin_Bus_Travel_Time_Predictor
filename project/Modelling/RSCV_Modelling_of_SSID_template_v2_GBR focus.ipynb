{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First set number of cores on machine to use and SSID number to analyse, then run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting variables\n",
    "\n",
    "cores = x # enter the number of cores to use here, in place of x\n",
    "SSIDno = xxxxxxxx # enter the SSID number to model as an int here, in place of xxxxxxxx\n",
    "iters = x # enter the number of randomised search iterations here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.patches as mpatches\n",
    "#import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "import autotime\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "#import seaborn as sns\n",
    "import statsmodels as stm\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression as LinR\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data processing stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, select route files to input based on SSIDno to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a Inputting data and creating dataframe for SSIDno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in stop_times.txt and trips.txt files from NTA data\n",
    "stop_times_2012 = pd.read_csv('stop_times.txt')\n",
    "trips_2012 = pd.read_csv('trips.txt')\n",
    "\n",
    "# Merge by trip_id\n",
    "merge = pd.merge(stop_times_2012, trips_2012, on='trip_id', how='outer')\n",
    "\n",
    "# Keep only necessary columns\n",
    "merge.drop(['arrival_time','departure_time','pickup_type','drop_off_type','service_id','shape_dist_traveled'], axis=1, inplace=True)\n",
    "\n",
    "# Transform trip_id to route and stop_id to StopID\n",
    "merge['route_short'] = merge['trip_id'].apply(lambda x: x[x.index('-')+1:])\n",
    "merge['route_short'] = merge['route_short'].apply(lambda x: x[: x.index('-')])\n",
    "merge['route_short'] = merge['route_short'].apply(lambda x: str(x).zfill(4))\n",
    "merge['StopID'] = merge['stop_id'].apply(lambda x: x[-4:])\n",
    "\n",
    "# Find StopID and the sequence of that shape_id\n",
    "gb = merge.groupby(['shape_id', 'route_short', 'direction_id','stop_sequence', 'StopID'])\n",
    "gbc = gb.count()\n",
    "gbc.reset_index(['shape_id', 'route_short', 'direction_id','stop_sequence', 'StopID'], inplace=True)\n",
    "transit_shapeID_stopID = gbc.drop(['trip_id','stop_id','route_id','trip_headsign'], axis=1)\n",
    "\n",
    "# create list of pairs of routes and the SSIDs contained within them\n",
    "ssid = []\n",
    "for i in range(len(transit_shapeID_stopID.index)-1):\n",
    "    temp = transit_shapeID_stopID['StopID'].iloc[i] + transit_shapeID_stopID['StopID'].iloc[i+1]\n",
    "    ssid.append([ transit_shapeID_stopID['route_short'].iloc[i],temp])\n",
    "    \n",
    "SSIDnoStr = str(SSIDno).zfill(8)\n",
    "routes = [x for x in ssid if SSIDnoStr in x[1]]\n",
    "routes = [item[0] for item in routes]\n",
    "routes = list(set(routes))\n",
    "\n",
    "# Reading in the route CSV files for the required SSID\n",
    "\n",
    "res = pd.read_csv('Route_XXXX_travel_time_csvs/Blank_Route_travel_time.csv')\n",
    "route_list = routes\n",
    "for r in route_list:\n",
    "    df = pd.read_csv('Route_XXXX_travel_time_csvs/Route_%s_travel_time.csv' % r)\n",
    "    res = pd.concat([df, res], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dataframe for SSIDno\n",
    "\n",
    "res['SSID'] = res['SSID'].astype('category')\n",
    "ssid_df = res[res.SSID == SSIDno]\n",
    "ssid_df.reset_index(inplace=True)\n",
    "ssid_df = ssid_df.drop('index', axis=1)\n",
    "ssid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JPID_Count = ssid_df.JourneyPatternID.unique().shape[0]\n",
    "Row_Count = ssid_df.shape[0]\n",
    "print(\"There are\", JPID_Count, \"unique JPIDs traversing this segment, over the course of\", Row_Count, \"observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add leading zeroes to JourneyPatternID\n",
    "\n",
    "ssid_df.JourneyPatternID = ssid_df.JourneyPatternID.astype('object')\n",
    "ssid_df.JourneyPatternID = ssid_df.JourneyPatternID.apply(lambda x: str(x).zfill(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b Adding extra features and altering/dropping existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding Xbuses feature - boolean feature indicating whether or not the JourneyPatternID represents an express (X) bus\n",
    "\n",
    "ssid_df['XBuses'] = ssid_df[ssid_df[\"JourneyPatternID\"].str.find(\"X\") > 0].sum(axis=1) > 0\n",
    "ssid_df[\"XBuses\"].fillna(False, inplace=True)\n",
    "ssid_df['XBuses'] = ssid_df['XBuses'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding JPID_length feature - represents the total number of stops traversed by this JourneyPatternID along its entire route\n",
    "\n",
    "JPIDL = pd.read_csv('JPID_Length.csv')\n",
    "JPIDL = JPIDL.drop('Unnamed: 0', axis=1)\n",
    "ssid_df = pd.merge(left=ssid_df ,right=JPIDL, how='left', left_on='JourneyPatternID', right_on='JourneyPatternID')\n",
    "ssid_df = ssid_df.dropna()\n",
    "ssid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing non-holiday-period weekends from SchoolHoliday feature to avoid multi-collinearity issues\n",
    "\n",
    "ssid_df['SchoolHoliday'] = ssid_df['SchoolHoliday'].astype('int')\n",
    "ssid_df['SchoolHoliday'] = np.where(ssid_df['TimeFrame'].isin(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "\n",
    "ssid_df = ssid_df.drop(['SourceStopID', 'DestStopID', 'VehicleJourneyID', 'JourneyPatternID', 'SSID'], axis=1)\n",
    "\n",
    "# reordering remaining columns\n",
    "\n",
    "ssid_df = ssid_df[['TravelTime', 'Rain', 'WindSpeed', 'JPID_length', 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assigning appropriate datatypes where necessary\n",
    "\n",
    "ssid_df['Day'] = ssid_df['Day'].astype('category')\n",
    "ssid_df['HourFrame'] = ssid_df['HourFrame'].astype('category')\n",
    "ssid_df['JPID_length'] = ssid_df['JPID_length'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing any constant features\n",
    "# code from: https://stackoverflow.com/questions/20209600/panda-dataframe-remove-constant-column\n",
    "\n",
    "ssid_df = ssid_df.loc[:,ssid_df.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Dropping Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising range of travel-time data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histiogram of values (x-axis is number of seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking stats for TravelTime\n",
    "\n",
    "ssid_df.TravelTime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading table of minimum times to traverse segments at 65kmph\n",
    "\n",
    "find_lb = pd.read_csv('use_speed_and_distance_get_outlier_bound.csv')\n",
    "\n",
    "# extracting value for this segment, to use as lower bound for outlier removal\n",
    "\n",
    "lb = find_lb.loc[find_lb['SSID'] == SSIDno, 'min_sec'].iloc[0]\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a copy of original df\n",
    "\n",
    "trimssid_df = ssid_df.copy()\n",
    "\n",
    "# Remove TravelTime upper bound outliers beyond 3 x IQR, and lowerbound below 'lb'\n",
    "\n",
    "ub = trimssid_df.quantile(q=.75) + (3*(trimssid_df.quantile(q=.75)-trimssid_df.quantile(q=.25)))\n",
    "trimssid_df['OutlierTT'] = (trimssid_df['TravelTime'] < lb) | (trimssid_df['TravelTime'] > ub['TravelTime'])\n",
    "\n",
    "# Outlier rows counted\n",
    "\n",
    "Outlier_Count = trimssid_df[(trimssid_df['OutlierTT'] == True)].shape[0]\n",
    "Row_Count = Row_Count - Outlier_Count\n",
    "\n",
    "print(\"There will be\", Outlier_Count, \"outliers dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping outliers\n",
    "\n",
    "trimssid_df = trimssid_df[trimssid_df.OutlierTT != True]\n",
    "trimssid_df.sort_values(['TravelTime'], ascending=False, inplace=True)\n",
    "trimssid_df = trimssid_df.drop(['OutlierTT'], axis=1)\n",
    "trimssid_df.reset_index(inplace=True)\n",
    "trimssid_df = trimssid_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create TT mean/median value variables, to use in calculating mean/median absolute percentage accuracy scores\n",
    "# and for horizontal lines in the charts below to represent the mean/medium\n",
    "\n",
    "ssid_df = trimssid_df\n",
    "ssid_df_mean = ssid_df.TravelTime.mean()\n",
    "ssid_df_median  = ssid_df.TravelTime.median()\n",
    "ssid_df.TravelTime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising range of data after dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ai Bar plot for mean TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_HF = ssid_df.groupby('HourFrame')['TravelTime'].mean()\n",
    "mean_HF.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 25\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2aii Bar plot for median TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_HF = ssid_df.groupby('HourFrame')['TravelTime'].median()\n",
    "med_HF.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 25\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2bi Bar plot for mean TravelTime per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_Day = ssid_df.groupby('Day')['TravelTime'].mean()\n",
    "mean_Day=mean_Day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "mean_Day.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2bii Bar plot for median TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_Day = ssid_df.groupby('Day')['TravelTime'].median()\n",
    "\n",
    "med_Day=med_Day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "med_Day.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ci Bar plot for mean TravelTime when SchoolHoliday true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_SH = ssid_df.groupby('SchoolHoliday')['TravelTime'].mean()\n",
    "mean_SH.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2cii Bar plot for median TravelTime when SchoolHoliday true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "med_SH = ssid_df.groupby('SchoolHoliday')['TravelTime'].median()\n",
    "med_SH.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% for training and 30% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model training (Scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to dreate dummy variables for categorical features, and split into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare data for modelling via Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummy variables from HourFrame and Day using get_dummies\n",
    "# dropping first values to avoid multicollinearity (Day = Friday, Hour = 0 or 6 or 7, depending on SSID)\n",
    "\n",
    "Day_dummies = pd.get_dummies(ssid_df.Day, prefix='Day', drop_first=True)\n",
    "HF_dummies = pd.get_dummies(ssid_df.HourFrame, prefix='HF', drop_first=True)\n",
    "\n",
    "# concatenate the dummy variable columns onto the original DataFrame and drop the original features\n",
    "ssid_df = pd.concat([ssid_df, HF_dummies, Day_dummies], axis=1)\n",
    "ssid_df = ssid_df.drop(['HourFrame', 'Day'], axis=1)\n",
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare a list containing all remaining features bar the target\n",
    "pred_features = list(ssid_df)\n",
    "pred_features.remove('TravelTime')\n",
    "print(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare target/predictive feature variables for use in scikit-learn modelling\n",
    "\n",
    "X = ssid_df[pred_features]\n",
    "y = ssid_df['TravelTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training portion (70%) and final testing potion (30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison purposes, first train on Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2a Linear Regression model (via scikit-learn) - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LinR(n_jobs = cores)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr_pred = lr.predict(X_train)\n",
    "lr_rsq = metrics.r2_score(y_train, lr_pred)\n",
    "print (\"The R-squared value of the Linear Regression model is\", lr_rsq)\n",
    "print()\n",
    "lr_mae = metrics.mean_absolute_error(y_train, lr_pred)\n",
    "print (\"The mean absolute error of the Linear Regression model is\", lr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((lr_mae)/ssid_df_mean)*100))\n",
    "print()\n",
    "lr_mdae = metrics.median_absolute_error(y_train, lr_pred)\n",
    "print (\"The median absolute error of the Linear Regression model is\", lr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((lr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2b Linear Regression model (via scikit-learn) - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_preda = lr.predict(X_test)\n",
    "lr_rsqa = metrics.r2_score(y_test, lr_preda)\n",
    "print (\"The R-squared value of the Linear Regression model is\", lr_rsqa)\n",
    "print()\n",
    "lr_maea = metrics.mean_absolute_error(y_test, lr_preda)\n",
    "print (\"The mean absolute error of the Linear Regression model is\", lr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((lr_maea)/ssid_df_mean)*100))\n",
    "print()\n",
    "lr_mdaea = metrics.median_absolute_error(y_test, lr_preda)\n",
    "print (\"The median absolute error of the Linear Regression model is\", lr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((lr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3a Gradient Boosting Regression model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR()\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3b Gradient Boosting Regression model - - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4a Gradient Boosting Regression model - training - LAD loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR(loss='lad')\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4b Gradient Boosting Regression model - testing - LAD loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5a Gradient Boosting Regression model - training - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsq)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_mae)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5b Gradient Boosting Regression model - testing - HUBER loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsqa = metrics.r2_score(y_test, gbr_preda)\n",
    "gbr_maea = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "gbr_mdaea = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the trained Gradient Boosting Regression model is\", gbr_rsqa)\n",
    "print ()\n",
    "print (\"The mean absolute error of the trained Gradient Boosting Regression model is\", gbr_maea)\n",
    "print (\"The mean absolute percentage error is\", (((gbr_maea)/ssid_df_mean)*100))\n",
    "print ()\n",
    "print (\"The median absolute error of the trained Gradient Boosting Regression model is\", gbr_mdaea)\n",
    "print (\"The median absolute percentage error is\", (((gbr_mdaea)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Parameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Note that there are\", JPID_Count, \"unique JPIDs traversing this segment, over the course of\", Row_Count, \"observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP HERE - from results above, select best loss function for each of the three trainings below,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a Gradient Boosted Regression with RandomizedSearchCV (scikit), Kfold 5, 5 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with Median Absolute Error as scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(75, 1500),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(5, 100),\n",
    "            'min_samples_split': stats.randint(200, 1000),\n",
    "            'learning_rate': stats.uniform(0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.median_absolute_error, greater_is_better=False))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_train_MdAE = abs(gbr_rsearch.best_score_)\n",
    "gbr_train_MdAPE = (gbr_train_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"Best MdAE found is\", gbr_train_MdAE)\n",
    "print (\"Best MdAPE found is\", str(round(gbr_train_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_learning_rate', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with Mean Absolute Error as scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(75, 1500),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(5, 100),\n",
    "            'min_samples_split': stats.randint(200, 1000),\n",
    "            'learning_rate': stats.uniform(0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.mean_absolute_error, greater_is_better=False))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_train_MAE = abs(gbr_rsearch.best_score_)\n",
    "gbr_train_MAPE = (gbr_train_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"Best Mean absolute error found is\", gbr_train_MAE)\n",
    "print (\"Best Mean absolute percentage error found is\", str(round(gbr_train_MAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_learning_rate', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with R-squared value as scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR(loss='huber')\n",
    "\n",
    "param_gbr = {'n_estimators': stats.randint(75, 1500),\n",
    "            'max_depth': stats.randint(3, 10),\n",
    "            'min_samples_leaf': stats.randint(5, 100),\n",
    "            'min_samples_split': stats.randint(200, 1000),\n",
    "            'learning_rate': stats.uniform(0.01, 0.3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_rsearch = RSCV(gbr, param_distributions=param_gbr, n_iter=iters, cv=5, n_jobs=cores, scoring=make_scorer(metrics.r2_score))\n",
    "gbr_rsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found:\")\n",
    "print(gbr_rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_train_rsqa = abs(gbr_rsearch.best_score_)\n",
    "\n",
    "print(\"Best R-squared value found is\", gbr_train_rsqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr_rsearch_table = pd.DataFrame(gbr_rsearch.cv_results_)\n",
    "gbr_rsearch_table.sort_values(['rank_test_score'], inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table[['rank_test_score', 'mean_train_score', 'mean_test_score', 'param_n_estimators', 'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split', 'param_learning_rate', 'mean_fit_time', 'mean_score_time']]\n",
    "gbr_rsearch_table.reset_index(inplace=True)\n",
    "gbr_rsearch_table = gbr_rsearch_table.drop('index', axis=1)\n",
    "\n",
    "print(\"Full ranked results for GBR RandomizedSearchCV:\")\n",
    "gbr_rsearch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running model on 30% test set\n",
    "\n",
    "gbr_test_pred = gbr_rsearch.best_estimator_.predict(X_test)\n",
    "\n",
    "gbr_test_rsqa = metrics.r2_score(y_test, gbr_test_pred)\n",
    "gbr_test_MAE = metrics.mean_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MAPE = (gbr_test_MAE/ssid_df_median)*100\n",
    "gbr_test_MdAE = metrics.median_absolute_error(y_test, gbr_test_pred)\n",
    "gbr_test_MdAPE = (gbr_test_MdAE/ssid_df_median)*100\n",
    "\n",
    "print(\"R-squared value of best model on the test set is\", gbr_test_rsqa)\n",
    "print()\n",
    "print(\"Mean absolute error of best model on the test set is\", gbr_test_MAE)\n",
    "print (\"Mean absolute percentage error of best model on the test set is\", str(round(gbr_test_MAPE, 3)) + \"%\")\n",
    "print()\n",
    "print(\"Median absolute error of best model on the test set is\", gbr_test_MdAE)\n",
    "print (\"Median absolute percentage error of best model on the test set is\", str(round(gbr_test_MdAPE, 3)) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DublinBus]",
   "language": "python",
   "name": "conda-env-DublinBus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
