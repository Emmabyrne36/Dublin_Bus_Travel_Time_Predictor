{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.patches as mpatches\n",
    "#import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "import autotime\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "#import seaborn as sns\n",
    "import statsmodels as stm\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression as LinR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import AdaBoostRegressor as ABR\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import GridSearchCV as GSCV\n",
    "from dask_searchcv import GridSearchCV as DGSCV\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "#from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting variables\n",
    "cores = x # enter number of cores on your machine to use here, replacing x\n",
    "SSIDno = xxxxxxxx # enter SSID number to analyse here, replacing xxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, select route files to input based on SSIDno to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in stop_times.txt and trips.txt files from NTA data\n",
    "stop_times_2012 = pd.read_csv('stop_times.txt')\n",
    "trips_2012 = pd.read_csv('trips.txt')\n",
    "\n",
    "# Merge by trip_id\n",
    "merge = pd.merge(stop_times_2012, trips_2012, on='trip_id', how='outer')\n",
    "\n",
    "# Keep only necessary columns\n",
    "merge.drop(['arrival_time','departure_time','pickup_type','drop_off_type','service_id','shape_dist_traveled'], axis=1, inplace=True)\n",
    "\n",
    "# Transform trip_id to route and stop_id to StopID\n",
    "merge['route_short'] = merge['trip_id'].apply(lambda x: x[x.index('-')+1:])\n",
    "merge['route_short'] = merge['route_short'].apply(lambda x: x[: x.index('-')])\n",
    "merge['route_short'] = merge['route_short'].apply(lambda x: str(x).zfill(4))\n",
    "merge['StopID'] = merge['stop_id'].apply(lambda x: x[-4:])\n",
    "\n",
    "# Find StopID and the sequence of that shape_id\n",
    "gb = merge.groupby(['shape_id', 'route_short', 'direction_id','stop_sequence', 'StopID'])\n",
    "gbc = gb.count()\n",
    "gbc.reset_index(['shape_id', 'route_short', 'direction_id','stop_sequence', 'StopID'], inplace=True)\n",
    "transit_shapeID_stopID = gbc.drop(['trip_id','stop_id','route_id','trip_headsign'], axis=1)\n",
    "\n",
    "# create list of pairs of routes and the SSIDs contained within them\n",
    "ssid = []\n",
    "for i in range(len(transit_shapeID_stopID.index)-1):\n",
    "    temp = transit_shapeID_stopID['StopID'].iloc[i] + transit_shapeID_stopID['StopID'].iloc[i+1]\n",
    "    ssid.append([ transit_shapeID_stopID['route_short'].iloc[i],temp])\n",
    "    \n",
    "SSIDnoStr = str(SSIDno).zfill(8)\n",
    "routes = [x for x in ssid if SSIDnoStr in x[1]]\n",
    "routes = [item[0] for item in routes]\n",
    "routes = list(set(routes))\n",
    "\n",
    "# Reading in the data and preparing the SSID dataframe\n",
    "\n",
    "res = pd.read_csv('Route_XXXX_travel_time_csvs/Blank_Route_travel_time.csv')\n",
    "route_list = routes\n",
    "for r in route_list:\n",
    "    df = pd.read_csv('Route_XXXX_travel_time_csvs/Route_%s_travel_time.csv' % r)\n",
    "    res = pd.concat([df, res], axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reading in the data and preparing the SSID dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check unique values of each feature\n",
    "\n",
    "print(\"Feature, UniqueValues\") \n",
    "for column in res:\n",
    "    print(column + \"\\t\" + str(len(res[column].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dataframe for SSID\n",
    "\n",
    "res['SSID'] = res['SSID'].astype('category')\n",
    "ssid_df = res[res.SSID == SSIDno] \n",
    "ssid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check unique values of each feature\n",
    "\n",
    "print(\"Feature, UniqueValues\") \n",
    "for column in ssid_df:\n",
    "    print(column + \"\\t\" + str(len(ssid_df[column].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.reset_index(inplace=True)\n",
    "ssid_df = ssid_df.drop('index', axis=1)\n",
    "ssid_df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df['JourneyPatternID'] = ssid_df['JourneyPatternID'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding Xbuses feature - boolean feature indicating whether or not the JourneyPatternID represents an express (X) bus\n",
    "\n",
    "ssid_df['XBuses'] = ssid_df[ssid_df[\"JourneyPatternID\"].str.find(\"X\") > 0].sum(axis=1) > 0\n",
    "ssid_df[\"XBuses\"].fillna(False, inplace=True)\n",
    "ssid_df['XBuses'] = ssid_df['XBuses'].astype('int')\n",
    "\n",
    "ssid_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding JPID_length feature - represents the total number of stops traversed by this JourneyPatternID along its entire route\n",
    "\n",
    "JPIDL = pd.read_csv('JPID_Length.csv')\n",
    "JPIDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "JPIDL = JPIDL.drop('Unnamed: 0', axis=1)\n",
    "# ssid_df['JourneyPatternID'] = ssid_df['JourneyPatternID'].astype('category')\n",
    "ssid_df.JourneyPatternID = ssid_df.JourneyPatternID.apply(lambda x: str(x).zfill(8))\n",
    "ssid_df = pd.merge(left=ssid_df ,right=JPIDL, how='left', left_on='JourneyPatternID', right_on='JourneyPatternID')\n",
    "ssid_df = ssid_df.dropna()\n",
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding JPID_Freq feature - represents how often in the given data this JourneyPatternID traversed this segment\n",
    "\n",
    "ssid_df['JPID_Freq'] = ssid_df.groupby(['JourneyPatternID'])['JourneyPatternID'].transform('count')\n",
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing non-holiday-period weekends from SchoolHoliday feature to avoid multi-collinearity issues\n",
    "\n",
    "ssid_df['SchoolHoliday'] = ssid_df['SchoolHoliday'].astype('int')\n",
    "ssid_df['SchoolHoliday'] = np.where(ssid_df['TimeFrame'].isin(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fetching SSID number from dataframe for CSV file naming purposes\n",
    "\n",
    "res.SSID = res.SSID.apply(lambda x: str(int(x)).zfill(8))\n",
    "r = ssid_df.loc[0, 'SSID'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "\n",
    "ssid_df = ssid_df.drop(['SourceStopID', 'DestStopID', 'VehicleJourneyID', 'JourneyPatternID', 'SSID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reorder remaining columns\n",
    "\n",
    "ssid_df = ssid_df[['TravelTime', 'Rain', 'WindSpeed', 'JPID_length', 'JPID_Freq', 'XBuses', 'SchoolHoliday', 'Day', 'HourFrame']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cores = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssid_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assigning appropriate datatypes where necessary\n",
    "\n",
    "ssid_df['Day'] = ssid_df['Day'].astype('category')\n",
    "ssid_df['HourFrame'] = ssid_df['HourFrame'].astype('category')\n",
    "ssid_df['JPID_length'] = ssid_df['JPID_length'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save as csv\n",
    "\n",
    "\n",
    "ssid_df.to_csv('SSID_CSVs/SSID_%s.csv' % r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of target feature TravelTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histiogram of values (x-axis is number of seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.hist(figsize=(16, 8), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking stats for TravelTime\n",
    "\n",
    "ssid_df.TravelTime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading table of times to traverse segments at 80kmph\n",
    "\n",
    "find_lb = pd.read_csv('use_speed_and_distance_get_outlier_bound.csv')\n",
    "\n",
    "# extracting value for this segment, to use as lower bound for outlier removal\n",
    "\n",
    "lb = find_lb.loc[find_lb['SSID'] == 9090786, 'min_sec'].iloc[0]\n",
    "print(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a copy of original df\n",
    "\n",
    "trimssid_df = ssid_df.copy()\n",
    "\n",
    "# Remove TravelTime upper bound outliers beyond a conservative 2 x IQR, and lowerbound below 'lb'\n",
    "\n",
    "ub = trimssid_df.quantile(q=.75) + (2*(trimssid_df.quantile(q=.75)-trimssid_df.quantile(q=.25)))\n",
    "trimssid_df['OutlierTT'] = (trimssid_df['TravelTime'] < lb) | (trimssid_df['TravelTime'] > ub['TravelTime'])\n",
    "\n",
    "# Outlier rows counted\n",
    "\n",
    "print(\"There will be\", trimssid_df[(trimssid_df['OutlierTT'] == True)].shape[0], \"outliers dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping outliers\n",
    "\n",
    "trimssid_df = trimssid_df[trimssid_df.OutlierTT != True]\n",
    "trimssid_df.sort_values(['TravelTime'], ascending=False, inplace=True)\n",
    "trimssid_df = trimssid_df.drop(['OutlierTT'], axis=1)\n",
    "trimssid_df.reset_index(inplace=True)\n",
    "trimssid_df = trimssid_df.drop('index', axis=1)\n",
    "trimssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create TT mean/median value variables, to use in calculating mean/median absolute percentage accuracy scores\n",
    "# and for horizontal lines in the charts below to represent the mean/medium\n",
    "\n",
    "ssid_df = trimssid_df\n",
    "ssid_df_mean = ssid_df.TravelTime.mean()\n",
    "ssid_df_median  = ssid_df.TravelTime.median()\n",
    "ssid_df.TravelTime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_df.TravelTime.plot(kind='box', figsize=(8, 8), showfliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a Bar plot for mean TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_HF = ssid_df.groupby('HourFrame')['TravelTime'].mean()\n",
    "mean_HF.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 25\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b Bar plot for median TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_HF = ssid_df.groupby('HourFrame')['TravelTime'].median()\n",
    "med_HF.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 25\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a Bar plot for mean TravelTime per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_Day = ssid_df.groupby('Day')['TravelTime'].mean()\n",
    "mean_Day=mean_Day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "mean_Day.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b Bar plot for median TravelTime per HourFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_Day = ssid_df.groupby('Day')['TravelTime'].median()\n",
    "\n",
    "med_Day=med_Day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "med_Day.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a Bar plot for mean TravelTime when SchoolHoliday true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_SH = ssid_df.groupby('SchoolHoliday')['TravelTime'].mean()\n",
    "mean_SH.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_mean\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b Bar plot for median TravelTime when SchoolHoliday true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "med_SH = ssid_df.groupby('SchoolHoliday')['TravelTime'].median()\n",
    "med_SH.plot(kind='bar', figsize=(15, 6), rot=0)\n",
    "\n",
    "coord_x1 = -1\n",
    "coord_y1 = ssid_df_median\n",
    "coord_x2 = 7\n",
    "\n",
    "plt.plot([coord_x1, coord_x2], [coord_y1, coord_y1], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training (statsmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Linear Regression model (via statsmodels - to see p-values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% for training and 30% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code to split data taken from here: http://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "\n",
    "ssid_train=ssid_df.sample(frac=0.7, random_state=38)\n",
    "ssid_test=ssid_df.drop(ssid_train.index)\n",
    "print (\"Training set size is\",len(ssid_train))\n",
    "print (\"Training set size is\",len(ssid_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrle = sm.ols(formula=\"TravelTime ~ SchoolHoliday + WindSpeed + Rain + JPID_length + JPID_Freq + XBuses + C(HourFrame) + C(Day)\", data=ssid_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lrle.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the below doesn't work for some reason\n",
    "\n",
    "# repeat on test frame and return Adj. R-squared value\n",
    "\n",
    "#rsqa = stm.regression.linear_model.RegressionResults.rsquared_adj(lrle.predict(ssid_lin_test))\n",
    "#print (\"The predicted adjusted R-squared value on the test frame is\", rsqa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Repeat Linear Regression model via statsmodels with continuous features normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to normalise the relevant parts of the original data and then repeat the test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalising continuous features\n",
    "\n",
    "ssid_lin = ssid_df\n",
    "ssid_lin['WindSpeed'] = (ssid_lin['WindSpeed']-ssid_lin['WindSpeed'].min())/(ssid_lin['WindSpeed'].max()-ssid_lin['WindSpeed'].min())\n",
    "ssid_lin['Rain'] = (ssid_lin['Rain']-ssid_lin['Rain'].min())/(ssid_lin['Rain'].max()-ssid_lin['Rain'].min())\n",
    "ssid_lin['JPID_length'] = (ssid_lin['JPID_length']-ssid_lin['JPID_length'].min())/(ssid_lin['JPID_length'].max()-ssid_lin['JPID_length'].min())\n",
    "ssid_lin['JPID_Freq'] = (ssid_lin['JPID_Freq']-ssid_lin['JPID_Freq'].min())/(ssid_lin['JPID_Freq'].max()-ssid_lin['JPID_Freq'].min())\n",
    "ssid_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssid_lin_train=ssid_lin.sample(frac=0.7, random_state=38)\n",
    "ssid_lin_test=ssid_lin.drop(ssid_lin_train.index)\n",
    "print (\"Training set size is\",len(ssid_lin_train))\n",
    "print (\"Training set size is\",len(ssid_lin_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrle1 = sm.ols(formula=\"TravelTime ~ SchoolHoliday + WindSpeed + Rain + JPID_length + JPID_Freq + XBuses + C(HourFrame) + C(Day)\", data=ssid_lin_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lrle1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the below doesn't work for some reason\n",
    "\n",
    "# repeat on test frame and return Adj. R-squared value\n",
    "\n",
    "# rsqa = stm.regression.linear_model.RegressionResults.rsquared_adj(lrle.predict(ssid_lin_test))\n",
    "# print (\"The predicted adjusted R-squared value on the test frame is\", rsqa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training (Scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to dreate dummy variables for categorical features, and split into test and training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for modelling via Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummy variables from HourFrame and Day using get_dummies\n",
    "# dropping first values to avoid multicollinearity (Day = Friday, Hour = 0 or 6 or 7, depending on SSID)\n",
    "\n",
    "Day_dummies = pd.get_dummies(ssid_df.Day, prefix='Day', drop_first=True)\n",
    "HF_dummies = pd.get_dummies(ssid_df.HourFrame, prefix='HF', drop_first=True)\n",
    "\n",
    "# concatenate the dummy variable columns onto the original DataFrame and drop the original features\n",
    "ssid_df = pd.concat([ssid_df, HF_dummies, Day_dummies], axis=1)\n",
    "ssid_df = ssid_df.drop(['HourFrame', 'Day'], axis=1)\n",
    "ssid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove any constant features\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(ssid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare a list containing all remaining features bar the target\n",
    "pred_features = list(ssid_df)\n",
    "pred_features.remove('TravelTime')\n",
    "print(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare target/predictive feature variables for use in scikit-learn modelling\n",
    "\n",
    "X = ssid_df[pred_features]\n",
    "y = ssid_df['TravelTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training portion (70%) and final testing potion (30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a Linear Regression model (via scikit-learn) - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LinR(n_jobs = cores)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(X_train)\n",
    "lr_rsq = metrics.r2_score(y_train, lr_pred)\n",
    "print (\"The R-squared value of the Linear Regression model is\", lr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_mae = metrics.mean_absolute_error(y_train, lr_pred)\n",
    "print (\"The mean absolute error of the Linear Regression model is\", lr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((lr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_mdae = metrics.median_absolute_error(y_train, lr_pred)\n",
    "print (\"The median absolute error of the Linear Regression model is\", lr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((lr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b Linear Regression model (via scikit-learn) - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_preda = lr.predict(X_test)\n",
    "lr_rsq = metrics.r2_score(y_test, lr_preda)\n",
    "print (\"The R-squared value of the Linear Regression model is\", lr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_mae = metrics.mean_absolute_error(y_test, lr_preda)\n",
    "print (\"The mean absolute error of the Linear Regression model is\", lr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((lr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_mdae = metrics.median_absolute_error(y_test, lr_preda)\n",
    "print (\"The median absolute error of the Linear Regression model is\", lr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((lr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1a Support Vector Machine Regression with Linear Kernel model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin = SVR(kernel='linear')\n",
    "svr_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin_pred = svr_lin.predict(X_train)\n",
    "svr_lin_rsq = metrics.r2_score(y_train, svr_lin_pred)\n",
    "print (\"The R-squared value of the SVR with Linear Kernel model is\", svr_lin_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin_mae = metrics.mean_absolute_error(y_train, svr_lin_pred)\n",
    "print (\"The mean absolute error of the SVR with Linear Kernel model is\", svr_lin_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svr_lin_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin_mdae = metrics.median_absolute_error(y_train, svr_lin_pred)\n",
    "print (\"The median absolute error of the SVR with Linear Kernel model is\", svr_lin_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svr_lin_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1b Support Vector Machine Regression with Linear Kernel model - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin_preda = svr_lin.predict(X_test)\n",
    "svr_lin_rsq = metrics.r2_score(y_test, svr_lin_preda)\n",
    "print (\"The R-squared value of the SVR with Linear Kernel model is\", svr_lin_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin_mae = metrics.mean_absolute_error(y_test, svr_lin_preda)\n",
    "print (\"The mean absolute error of the SVR with Linear Kernel model is\", svr_lin_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svr_lin_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_lin_mdae = metrics.median_absolute_error(y_test, svr_lin_preda)\n",
    "print (\"The median absolute error of the SVR with Linear Kernel model is\", svr_lin_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svr_lin_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1c Repeat SVR with Linear Kernel model, continuous data normalised - training  - default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to normalise the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalising continuous features\n",
    "\n",
    "ssid_norm = ssid_df\n",
    "ssid_norm['WindSpeed'] = (ssid_norm['WindSpeed']-ssid_norm['WindSpeed'].min())/(ssid_norm['WindSpeed'].max()-ssid_norm['WindSpeed'].min())\n",
    "ssid_norm['Rain'] = (ssid_norm['Rain']-ssid_norm['Rain'].min())/(ssid_norm['Rain'].max()-ssid_norm['Rain'].min())\n",
    "ssid_norm['JPID_length'] = (ssid_norm['JPID_length']-ssid_norm['JPID_length'].min())/(ssid_norm['JPID_length'].max()-ssid_norm['JPID_length'].min())\n",
    "ssid_norm['JPID_Freq'] = (ssid_norm['JPID_Freq']-ssid_norm['JPID_Freq'].min())/(ssid_norm['JPID_Freq'].max()-ssid_norm['JPID_Freq'].min())\n",
    "ssid_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare a list containing all remaining features bar the target\n",
    "\n",
    "pred_features = list(ssid_norm)\n",
    "pred_features.remove('TravelTime')\n",
    "print(pred_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare farget/predictive feature variables for use in scikit-learn modelling\n",
    "\n",
    "X_norm = ssid_norm[pred_features]\n",
    "y_norm = ssid_norm['TravelTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training portion (70%) and final testing potion (30%)\n",
    "\n",
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(X_norm, y_norm, test_size = 0.3, random_state = 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin = SVR(kernel='linear')\n",
    "svrn_lin.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin_pred = svrn_lin.predict(X_train)\n",
    "svrn_lin_rsq = metrics.r2_score(yn_train, svrn_lin_pred)\n",
    "print (\"The R-squared value of the SVR with Linear Kernel model is\", svrn_lin_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin_mae = metrics.mean_absolute_error(y_train, svr_lin_pred)\n",
    "print (\"The mean absolute error of the SVR with Linear Kernel model is\", svrn_lin_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svrn_lin_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin_mdae = metrics.median_absolute_error(y_train, svr_lin_pred)\n",
    "print (\"The median absolute error of the SVR with Linear Kernel model is\", svrn_lin_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svrn_lin_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1d Repeat SVR with Linear Kernel model, continuous data normalised - testing  - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin_preda = svrn_lin.predict(Xn_test)\n",
    "svrn_lin_rsq = metrics.r2_score(yn_test, svrn_lin_preda)\n",
    "print (\"The R-squared value of the SVR with Linear Kernel model is\", svr_lin_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin_mae = metrics.mean_absolute_error(yn_test, svrn_lin_preda)\n",
    "print (\"The mean absolute error of the SVR with Linear Kernel model is\", svr_lin_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svrn_lin_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_lin_mdae = metrics.median_absolute_error(yn_test, svrn_lin_preda)\n",
    "print (\"The median absolute error of the SVR with Linear Kernel model is\", svr_lin_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svrn_lin_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2a Support Vector Machine Regression with Polynomial Kernel model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly = SVR(kernel='poly')\n",
    "svr_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly_pred = svr_poly.predict(X_train)\n",
    "svr_poly_rsq = metrics.r2_score(y_train, svr_poly_pred)\n",
    "print (\"The R-squared value of the SVR with Polynomial Kernel model is\", svr_poly_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly_mae = metrics.mean_absolute_error(y_train, svr_poly_pred)\n",
    "print (\"The mean absolute error of the SVR with Polynomial Kernel model is\", svr_poly_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svr_poly_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly_mdae = metrics.median_absolute_error(y_train, svr_poly_pred)\n",
    "print (\"The median absolute error of the SVR with Polynomial Kernel model is\", svr_poly_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svr_poly_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2b Support Vector Machine Regression with Polynomial Kernel model - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly_preda = svr_poly.predict(X_test)\n",
    "svr_poly_rsq = metrics.r2_score(y_test, svr_poly_preda)\n",
    "print (\"The R-squared value of the SVR with Polynomial Kernel model is\", svr_poly_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly_mae = metrics.mean_absolute_error(y_test, svr_poly_preda)\n",
    "print (\"The mean absolute error of the SVR with Polynomial Kernel model is\", svr_poly_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svr_poly_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_poly_mdae = metrics.median_absolute_error(y_test, svr_poly_preda)\n",
    "print (\"The median absolute error of the SVR with Polynomial Kernel model is\", svr_poly_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svr_poly_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2c Repeat SVR with Polynomial Kernel model, continuous data normalised - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly = SVR(kernel='poly')\n",
    "svrn_poly.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly_pred = svrn_poly.predict(Xn_train)\n",
    "svrn_poly_rsq = metrics.r2_score(yn_train, svrn_poly_pred)\n",
    "print (\"The R-squared value of the SVR with Polynomial Kernel model is\", svrn_poly_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly_mae = metrics.mean_absolute_error(yn_train, svrn_poly_pred)\n",
    "print (\"The mean absolute error of the SVR with Polynomial Kernel model is\", svrn_poly_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svrn_poly_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly_mdae = metrics.median_absolute_error(yn_train, svrn_poly_pred)\n",
    "print (\"The median absolute error of the SVR with Polynomial Kernel model is\", svrn_poly_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svrn_poly_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2d Repeat SVR with Polynomial Kernel model, continuous data normalised - testing  - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly_preda = svrn_poly.predict(Xn_test)\n",
    "svrn_poly_rsq = metrics.r2_score(yn_test, svrn_poly_preda)\n",
    "print (\"The R-squared value of the SVR with Polynomial Kernel model is\", svrn_poly_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly_mae = metrics.mean_absolute_error(yn_test, svrn_poly_preda)\n",
    "print (\"The mean absolute error of the SVR with Polynomial Kernel model is\", svrn_poly_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svrn_poly_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_poly_mdae = metrics.median_absolute_error(yn_test, svrn_poly_preda)\n",
    "print (\"The median absolute error of the SVR with Polynomial Kernel model is\", svrn_poly_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svrn_poly_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3a Support Vector Machine Regression with RBF Kernel model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf')\n",
    "svr_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf_pred = svr_rbf.predict(X_train)\n",
    "svr_rbf_rsq = metrics.r2_score(y_train, svr_rbf_pred)\n",
    "print (\"The R-squared value of the SVR with RBF Kernel model is\", svr_rbf_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf_mae = metrics.mean_absolute_error(y_train, svr_rbf_pred)\n",
    "print (\"The mean absolute error of the SVR with RBF Kernel model is\", svr_rbf_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svr_rbf_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf_mdae = metrics.median_absolute_error(y_train, svr_rbf_pred)\n",
    "print (\"The median absolute error of the SVR with RBF Kernel model is\", svr_rbf_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svr_rbf_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3b Support Vector Machine Regression with RBF Kernel model - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf_preda = svr_rbf.predict(X_test)\n",
    "svr_rbf_rsq = metrics.r2_score(y_test, svr_rbf_preda)\n",
    "print (\"The R-squared value of the SVR with RBF Kernel model is\", svr_rbf_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf_mae = metrics.mean_absolute_error(y_test, svr_rbf_preda)\n",
    "print (\"The mean absolute error of the SVR with RBF Kernel model is\", svr_rbf_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svr_rbf_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_rbf_mdae = metrics.median_absolute_error(y_test, svr_rbf_preda)\n",
    "print (\"The median absolute error of the SVR with RBF Kernel model is\", svr_rbf_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svr_rbf_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3c Repeat SVR with RBF Kernel model, continuous data normalised - training  - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf = SVR(kernel='rbf')\n",
    "svrn_rbf.fit(Xn_train, yn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf_pred = svrn_rbf.predict(Xn_train)\n",
    "svrn_rbf_rsq = metrics.r2_score(yn_train, svrn_rbf_pred)\n",
    "print (\"The R-squared value of the SVR with RBF Kernel model is\", svrn_rbf_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf_mae = metrics.mean_absolute_error(yn_train, svrn_rbf_pred)\n",
    "print (\"The mean absolute error of the SVR with RBF Kernel model is\", svrn_rbf_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svrn_rbf_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf_mdae = metrics.median_absolute_error(yn_train, svrn_rbf_pred)\n",
    "print (\"The median absolute error of the SVR with RBF Kernel model is\", svrn_rbf_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svrn_rbf_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3d Repeat SVR with RBF Kernel model, continuous data normalised - testing  - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf_preda = svrn_rbf.predict(Xn_test)\n",
    "svrn_rbf_rsq = metrics.r2_score(yn_test, svrn_rbf_preda)\n",
    "print (\"The R-squared value of the SVR with RBF Kernel model is\", svrn_rbf_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf_mae = metrics.mean_absolute_error(yn_test, svrn_rbf_preda)\n",
    "print (\"The mean absolute error of the SVR with RBF Kernel model is\", svrn_rbf_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((svrn_rbf_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svrn_rbf_mdae = metrics.median_absolute_error(yn_test, svrn_rbf_preda)\n",
    "print (\"The median absolute error of the SVR with RBF Kernel model is\", svrn_rbf_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((svrn_rbf_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a Decision Tree Regression model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code from here: https://gist.github.com/JustGlowing/fa2c0ac39415eb271db6\n",
    "\n",
    "dtr = DTR()\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing ranking of features by estimated predictive value for Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code adapted from http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "indices = np.argsort(dtr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", dtr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr_pred = dtr.predict(X_train)\n",
    "dtr_rsq = metrics.r2_score(y_train, dtr_pred)\n",
    "print (\"The R-squared value of the Decision Tree Regression model is\", dtr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr_mae = metrics.mean_absolute_error(y_train, dtr_pred)\n",
    "print (\"The mean absolute error of the Decision Tree Regression model is\", dtr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((dtr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr_mdae = metrics.median_absolute_error(y_train, dtr_pred)\n",
    "print (\"The median absolute error of the Decision Tree Regression model is\", dtr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((dtr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b Decision Tree Regression model - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr_preda = dtr.predict(X_test)\n",
    "dtr_rsq = metrics.r2_score(y_test, dtr_preda)\n",
    "print (\"The R-squared value of the Decision Tree Regression model is\", dtr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr_mae = metrics.mean_absolute_error(y_test, dtr_preda)\n",
    "print (\"The mean absolute error of the Decision Tree Regression model is\", dtr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((dtr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr_mdae = metrics.median_absolute_error(y_test, dtr_preda)\n",
    "print (\"The median absolute error of the Decision Tree Regression model is\", dtr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((dtr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a Decision Tree Regression with AdaBoost model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abr = ABR()\n",
    "abr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(abr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", dtr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abr_pred = abr.predict(X_train)\n",
    "abr_rsq = metrics.r2_score(y_train, abr_pred)\n",
    "print (\"The R-squared value of the Decision Tree Regression with AdaBoost model is\", abr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abr_mae = metrics.mean_absolute_error(y_train, abr_pred)\n",
    "print (\"The mean absolute error of the Decision Tree Regression with AdaBoost model is\", abr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((abr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abr_mdae = metrics.median_absolute_error(y_train, abr_pred)\n",
    "print (\"The median absolute error of the Decision Tree Regression with AdaBoost model is\", abr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((abr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b Decision Tree Regression with AdaBoost model - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abr_preda = abr.predict(X_test)\n",
    "abr_rsq = metrics.r2_score(y_test, abr_preda)\n",
    "print (\"The R-squared value of the Decision Tree Regression with AdaBoost model is\", abr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abr_mae = metrics.mean_absolute_error(y_test, abr_preda)\n",
    "print (\"The mean absolute error of the Decision Tree Regression with AdaBoost model is\", abr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((abr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abr_mdae = metrics.median_absolute_error(y_test, abr_preda)\n",
    "print (\"The median absolute error of the Decision Tree Regression with AdaBoost model is\", abr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((abr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a Gradient Boosting Regression model - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = GBR()\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(gbr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", gbr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_pred = gbr.predict(X_train)\n",
    "gbr_rsq = metrics.r2_score(y_train, gbr_pred)\n",
    "print (\"The R-squared value of the Gradient Boosting Regression model is\", gbr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_mae = metrics.mean_absolute_error(y_train, gbr_pred)\n",
    "print (\"The mean absolute error of the Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((gbr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_mdae = metrics.median_absolute_error(y_train, gbr_pred)\n",
    "print (\"The median absolute error of the Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b Gradient Boosting Regression model - - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_preda = gbr.predict(X_test)\n",
    "gbr_rsq = metrics.r2_score(y_test, gbr_preda)\n",
    "print (\"The R-squared value of the Gradient Boosting Regression model is\", gbr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_mae = metrics.mean_absolute_error(y_test, gbr_preda)\n",
    "print (\"The mean absolute error of the Gradient Boosting Regression model is\", gbr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((gbr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr_mdae = metrics.median_absolute_error(y_test, gbr_preda)\n",
    "print (\"The median absolute error of the Gradient Boosting Regression model is\", gbr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((gbr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a Random Forest Regression model (all default) - training - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RFR(n_jobs = cores)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(rfr.feature_importances_)[::-1]\n",
    "\n",
    "# Print the ordered feature ranking\n",
    "print(\"Ordered feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    feat = indices[f]\n",
    "    print(X_train.columns[feat], \"\\t\", dtr.feature_importances_[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_pred = rfr.predict(X_train)\n",
    "rfr_rsq = metrics.r2_score(y_train, rfr_pred)\n",
    "print (\"The R-squared value of the Random Forest Regression model is\", rfr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_mae = metrics.mean_absolute_error(y_train, rfr_pred)\n",
    "print (\"The mean absolute error of the Random Forest Regression model is\", rfr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((rfr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_mdae = metrics.median_absolute_error(y_train, rfr_pred)\n",
    "print (\"The median absolute error of the Random Forest Regression model is\", rfr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((rfr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b Random Forest Regression model (all default) - testing - default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_preda = rfr.predict(X_test)\n",
    "rfr_rsq = metrics.r2_score(y_test, rfr_preda)\n",
    "print (\"The R-squared value of the Random Forest Regression model is\", rfr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_mae = metrics.mean_absolute_error(y_test, rfr_preda)\n",
    "print (\"The mean absolute error of the Random Forest Regression model is\", rfr_mae)\n",
    "print (\"The mean absolute percentage accuracy is\", (((rfr_mae)/ssid_df_mean)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_mdae = metrics.median_absolute_error(y_test, rfr_preda)\n",
    "print (\"The median absolute error of the Random Forest Regression model is\", rfr_mdae)\n",
    "print (\"The median absolute percentage accuracy is\", (((rfr_mdae)/ssid_df_median)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression model - OTT Gridsearch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from this has been lost, but it took many hours to run.  Too many combinations of parameters chosen, as this method exhaustively models each and every one!  Decided RandomizedSearchCV would be more cost-effective approach better approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RFR()\n",
    "params = { \n",
    "    'n_estimators': [120, 300, 500, 800, 1200],\n",
    "    'max_depth':[5, 8, 15, 25, 30, None],\n",
    "    'min_samples_split':[1.0, 2, 5, 10, 15, 100],\n",
    "    'min_samples_leaf':[1, 2, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "CV_rfr = GSCV(estimator=rfr, param_grid=params, cv= 5)\n",
    "CV_rfr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (CV_rfr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CV_rfr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_pred = CV_rfr.predict(X)\n",
    "rfr_rsq = metrics.r2_score(y, rfr_pred)\n",
    "print (\"The R-squared value of the Random Forest Regression model is\", rfr_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_mae = metrics.mean_absolute_error(y, rfr_pred)\n",
    "print (\"The mean absolute error of the Random Forest Regression model is\", rfr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_mdae = metrics.median_absolute_error(y, rfr_pred)\n",
    "print (\"The median absolute error of the Random Forest Regression model is\", rfr_mdae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:  SVR is far too slow for our purposes with Linear or Polynomial kernels, but surprisingly is much quicker and more accurate with the RBF kernel - we will disregard the first two but continue testing the latter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DublinBus]",
   "language": "python",
   "name": "conda-env-DublinBus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
